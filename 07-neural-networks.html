<!DOCTYPE html>
<!-- START: inst/pkgdown/templates/layout.html --><!-- Generated by pkgdown: do not edit by hand --><html lang="en" data-bs-theme="auto"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><title>Introduction to Machine Learning with Scikit Learn: Neural Networks</title><meta name="viewport" content="width=device-width, initial-scale=1"><script src="assets/themetoggle.js"></script><link rel="stylesheet" type="text/css" href="assets/styles.css"><script src="assets/scripts.js" type="text/javascript"></script><!-- mathjax --><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      config: ["MMLorHTML.js"],
      jax: ["input/TeX","input/MathML","output/HTML-CSS","output/NativeMML", "output/PreviewHTML"],
      extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
      TeX: {
        extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
      },
      tex2jax: {
        inlineMath: [['\\(', '\\)']],
        displayMath: [ ['$$','$$'], ['\\[', '\\]'] ],
        processEscapes: true
      }
    });
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><!-- Responsive Favicon for The Carpentries --><link rel="apple-touch-icon" sizes="180x180" href="favicons/incubator/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="favicons/incubator/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="favicons/incubator/favicon-16x16.png"><link rel="manifest" href="favicons/incubator/site.webmanifest"><link rel="mask-icon" href="favicons/incubator/safari-pinned-tab.svg" color="#5bbad5"><meta name="msapplication-TileColor" content="#da532c"><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"><meta name="theme-color" media="(prefers-color-scheme: dark)" content="black"></head><body>
    <header id="top" class="navbar navbar-expand-md top-nav incubator"><svg xmlns="http://www.w3.org/2000/svg" class="d-none"><symbol id="check2" viewbox="0 0 16 16"><path d="M13.854 3.646a.5.5 0 0 1 0 .708l-7 7a.5.5 0 0 1-.708 0l-3.5-3.5a.5.5 0 1 1 .708-.708L6.5 10.293l6.646-6.647a.5.5 0 0 1 .708 0z"></path></symbol><symbol id="circle-half" viewbox="0 0 16 16"><path d="M8 15A7 7 0 1 0 8 1v14zm0 1A8 8 0 1 1 8 0a8 8 0 0 1 0 16z"></path></symbol><symbol id="moon-stars-fill" viewbox="0 0 16 16"><path d="M6 .278a.768.768 0 0 1 .08.858 7.208 7.208 0 0 0-.878 3.46c0 4.021 3.278 7.277 7.318 7.277.527 0 1.04-.055 1.533-.16a.787.787 0 0 1 .81.316.733.733 0 0 1-.031.893A8.349 8.349 0 0 1 8.344 16C3.734 16 0 12.286 0 7.71 0 4.266 2.114 1.312 5.124.06A.752.752 0 0 1 6 .278z"></path><path d="M10.794 3.148a.217.217 0 0 1 .412 0l.387 1.162c.173.518.579.924 1.097 1.097l1.162.387a.217.217 0 0 1 0 .412l-1.162.387a1.734 1.734 0 0 0-1.097 1.097l-.387 1.162a.217.217 0 0 1-.412 0l-.387-1.162A1.734 1.734 0 0 0 9.31 6.593l-1.162-.387a.217.217 0 0 1 0-.412l1.162-.387a1.734 1.734 0 0 0 1.097-1.097l.387-1.162zM13.863.099a.145.145 0 0 1 .274 0l.258.774c.115.346.386.617.732.732l.774.258a.145.145 0 0 1 0 .274l-.774.258a1.156 1.156 0 0 0-.732.732l-.258.774a.145.145 0 0 1-.274 0l-.258-.774a1.156 1.156 0 0 0-.732-.732l-.774-.258a.145.145 0 0 1 0-.274l.774-.258c.346-.115.617-.386.732-.732L13.863.1z"></path></symbol><symbol id="sun-fill" viewbox="0 0 16 16"><path d="M8 12a4 4 0 1 0 0-8 4 4 0 0 0 0 8zM8 0a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 0zm0 13a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 13zm8-5a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2a.5.5 0 0 1 .5.5zM3 8a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2A.5.5 0 0 1 3 8zm10.657-5.657a.5.5 0 0 1 0 .707l-1.414 1.415a.5.5 0 1 1-.707-.708l1.414-1.414a.5.5 0 0 1 .707 0zm-9.193 9.193a.5.5 0 0 1 0 .707L3.05 13.657a.5.5 0 0 1-.707-.707l1.414-1.414a.5.5 0 0 1 .707 0zm9.193 2.121a.5.5 0 0 1-.707 0l-1.414-1.414a.5.5 0 0 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .707zM4.464 4.465a.5.5 0 0 1-.707 0L2.343 3.05a.5.5 0 1 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .708z"></path></symbol></svg><a class="visually-hidden-focusable skip-link" href="#main-content">Skip to main content</a>
  <div class="container-fluid top-nav-container">
    <div class="col-md-8">
      <div class="large-logo">
        <img id="incubator-logo" alt="Carpentries Incubator" src="assets/images/incubator-logo.svg"><span class="badge text-bg-warning">
          <abbr title="This lesson is in the alpha phase, which means that it has been taught once and lesson authors are iterating on feedback.">
            <a href="https://docs.carpentries.org/resources/curriculum/lesson-life-cycle.html" class="external-link alert-link">
              <i aria-hidden="true" class="icon" data-feather="alert-triangle" style="border-radius: 5px"></i>
              Alpha
            </a>
            <span class="visually-hidden">This lesson is in the alpha phase, which means that it has been taught once and lesson authors are iterating on feedback.</span>
          </abbr>
        </span>

      </div>
    </div>
    <div class="selector-container">
      <div id="theme-selector">
        <li class="nav-item dropdown" id="theme-button-list">
          <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
            <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="bd-theme-text"><li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                Light
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                Dark
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                Auto
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
          </ul></li>
      </div>

      <div class="dropdown" id="instructor-dropdown">
        <button class="btn btn-secondary dropdown-toggle bordered-button" type="button" id="dropdownMenu1" data-bs-toggle="dropdown" aria-expanded="false">
          <i aria-hidden="true" class="icon" data-feather="eye"></i> Learner View <i data-feather="chevron-down"></i>
        </button>
        <ul class="dropdown-menu" aria-labelledby="dropdownMenu1"><li><button class="dropdown-item" type="button" onclick="window.location.href='instructor/07-neural-networks.html';">Instructor View</button></li>
        </ul></div>
    </div>
  </div>
  <hr></header><nav class="navbar navbar-expand-xl bottom-nav incubator" aria-label="Main Navigation"><div class="container-fluid nav-container">
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle Navigation">
      <span class="navbar-toggler-icon"></span>
      <span class="menu-title">Menu</span>
    </button>
    <div class="nav-logo">
      <img class="small-logo" alt="Carpentries Incubator" src="assets/images/incubator-logo-sm.svg"></div>
    <div class="lesson-title-md">
      Introduction to Machine Learning with Scikit Learn
    </div>
    <div class="search-icon-sm">
      <!-- TODO: do not show until we have search
        <i role="img" aria-label="Search the All In One page" data-feather="search"></i>
      -->
    </div>
    <div class="desktop-nav">
      <ul class="navbar-nav me-auto mb-2 mb-lg-0"><li class="nav-item">
          <span class="lesson-title">
            Introduction to Machine Learning with Scikit Learn
          </span>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="key-points.html">Key Points</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="reference.html#glossary">Glossary</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="profiles.html">Learner Profiles</a>
        </li>
        <li class="nav-item dropdown">
          <button class="nav-link dropdown-toggle" id="navbarDropdown" data-bs-toggle="dropdown" aria-expanded="false">
            More <i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu" aria-labelledby="navbarDropdown"><li><a class="dropdown-item" href="reference.html">Reference</a></li>
          </ul></li>
      </ul></div>
    <!--
    <form class="d-flex col-md-2 search-form">
      <fieldset disabled>
      <input class="form-control me-2 searchbox" type="search" placeholder="" aria-label="">
        <button class="btn btn-outline-success tablet-search-button"  type="submit">
          <i class="search-icon" data-feather="search" role="img" aria-label="Search the All In One page"></i>
        </button>
      </fieldset>
    </form>
    -->
    <a id="search-button" class="btn btn-primary" href="aio.html" role="button" aria-label="Search the All In One page">Search the All In One page</a>
  </div><!--/div.container-fluid -->
</nav><div class="col-md-12 mobile-title">
  Introduction to Machine Learning with Scikit Learn
</div>

<aside class="col-md-12 lesson-progress"><div style="width: 86%" class="percentage">
    86%
  </div>
  <div class="progress incubator">
    <div class="progress-bar incubator" role="progressbar" style="width: 86%" aria-valuenow="86" aria-label="Lesson Progress" aria-valuemin="0" aria-valuemax="100">
    </div>
  </div>
</aside><div class="container">
      <div class="row">
        <!-- START: inst/pkgdown/templates/navbar.html -->
<div id="sidebar-col" class="col-lg-4">
  <div id="sidebar" class="sidebar">
      <nav aria-labelledby="flush-headingEleven"><button role="button" aria-label="close menu" alt="close menu" aria-expanded="true" aria-controls="sidebar" class="collapse-toggle" data-collapse="Collapse " data-episodes="Episodes ">
          <i class="search-icon" data-feather="x" role="img"></i>
        </button>
        <div class="sidebar-inner">
          <div class="row mobile-row" id="theme-row-mobile">
            <div class="col" id="theme-selector">
              <li class="nav-item dropdown" id="theme-button-list">
                <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
                  <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><span class="d-lg-none ms-1" id="bd-theme-text">Toggle Theme</span>
                </button>
                <ul class="dropdown-menu dropdown-menu-right" aria-labelledby="bd-theme-text"><li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                      Light
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                      Dark
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                      <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                      Auto
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                </ul></li>
            </div>
          </div>
          <div class="row mobile-row">
            <div class="col">
              <div class="sidenav-view-selector">
                <div class="accordion accordion-flush" id="accordionFlush9">
                  <div class="accordion-item">
                    <h2 class="accordion-header" id="flush-headingNine">
                      <button class="accordion-button collapsed" id="instructor" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseNine" aria-expanded="false" aria-controls="flush-collapseNine">
                        <i id="eye" aria-hidden="true" class="icon" data-feather="eye"></i> Learner View
                      </button>
                    </h2>
                    <div id="flush-collapseNine" class="accordion-collapse collapse" aria-labelledby="flush-headingNine" data-bs-parent="#accordionFlush2">
                      <div class="accordion-body">
                        <a href="instructor/07-neural-networks.html">Instructor View</a>
                      </div>
                    </div>
                  </div><!--/div.accordion-item-->
                </div><!--/div.accordion-flush-->
              </div><!--div.sidenav-view-selector -->
            </div><!--/div.col -->

            <hr></div><!--/div.mobile-row -->

          <div class="accordion accordion-flush" id="accordionFlush11">
            <div class="accordion-item">

              <button id="chapters" class="accordion-button show" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseEleven" aria-expanded="false" aria-controls="flush-collapseEleven">
                <h2 class="accordion-header chapters" id="flush-headingEleven">
                  EPISODES
                </h2>
              </button>
              <div id="flush-collapseEleven" class="accordion-collapse show collapse" aria-labelledby="flush-headingEleven" data-bs-parent="#accordionFlush11">

                <div class="accordion-body">
                  <div class="accordion accordion-flush" id="accordionFlush1">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading1">
        <a href="index.html">Summary and Setup</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush2">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading2">
        <a href="01-introduction.html">1. Introduction</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush3">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading3">
        <a href="02-regression.html">2. Supervised methods - Regression</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush4">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading4">
        <a href="03-classification.html">3. Supervised methods - Classification</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush5">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading5">
        <a href="04-ensemble-methods.html">4. Ensemble methods</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush6">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading6">
        <a href="05-clustering.html">5. Unsupervised methods - Clustering</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush7">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading7">
        <a href="06-dimensionality-reduction.html">6. Unsupervised methods - Dimensionality reduction</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlushcurrent">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-headingcurrent">
      <button class="accordion-button" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapsecurrent" aria-expanded="true" aria-controls="flush-collapsecurrent">
        <span class="visually-hidden">Current Chapter</span>
        <span class="current-chapter">
        7. Neural Networks
        </span>
      </button>
    </div><!--/div.accordion-header-->

    <div id="flush-collapsecurrent" class="accordion-collapse collapse show" aria-labelledby="flush-headingcurrent" data-bs-parent="#accordionFlushcurrent">
      <div class="accordion-body">
        <ul><li><a href="#neural-networks">Neural networks</a></li>
<li><a href="#perceptrons">Perceptrons</a></li>
<li><a href="#multi-layer-perceptrons">Multi-layer perceptrons</a></li>
<li><a href="#measuring-neural-network-performance">Measuring neural network performance</a></li>
<li><a href="#cross-validation">Cross-validation</a></li>
<li><a href="#deep-learning">Deep learning</a></li>
        </ul></div><!--/div.accordion-body-->
    </div><!--/div.accordion-collapse-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush9">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading9">
        <a href="08-ethics.html">8. Ethics and the Implications of Machine Learning</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush10">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading10">
        <a href="09-learn-more.html">9. Find out more</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

                </div>
              </div>
            </div>

            <hr class="half-width"><div class="accordion accordion-flush lesson-resources" id="accordionFlush12">
              <div class="accordion-item">
                <h2 class="accordion-header" id="flush-headingTwelve">
                  <button class="accordion-button collapsed" id="lesson-resources" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseTwelve" aria-expanded="false" aria-controls="flush-collapseTwelve">
                    RESOURCES
                  </button>
                </h2>
                <div id="flush-collapseTwelve" class="accordion-collapse collapse" aria-labelledby="flush-headingTwelve" data-bs-parent="#accordionFlush12">
                  <div class="accordion-body">
                    <ul><li>
                        <a href="key-points.html">Key Points</a>
                      </li>
                      <li>
                        <a href="reference.html#glossary">Glossary</a>
                      </li>
                      <li>
                        <a href="profiles.html">Learner Profiles</a>
                      </li>
                      <li><a href="reference.html">Reference</a></li>
                    </ul></div>
                </div>
              </div>
            </div>
            <hr class="half-width lesson-resources"><a href="aio.html">See all in one page</a>


            <hr class="d-none d-sm-block d-md-none"><div class="d-grid gap-1">

            </div>
          </div><!-- /div.accordion -->
        </div><!-- /div.sidebar-inner -->
      </nav></div><!-- /div.sidebar -->
  </div><!-- /div.sidebar-col -->
<!-- END:   inst/pkgdown/templates/navbar.html-->

        <!-- START: inst/pkgdown/templates/content-instructor.html -->
  <div class="col-xl-8 col-lg-12 primary-content">
    <nav class="lesson-content mx-md-4" aria-label="Previous and Next Chapter"><!-- content for small screens --><div class="d-block d-sm-block d-md-none">
        <a class="chapter-link" href="06-dimensionality-reduction.html"><i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>Previous</a>
        <a class="chapter-link float-end" href="08-ethics.html">Next<i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i></a>
      </div>
      <!-- content for large screens -->
      <div class="d-none d-sm-none d-md-block">
        <a class="chapter-link" href="06-dimensionality-reduction.html" rel="prev">
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>
          Previous: Unsupervised methods
        </a>
        <a class="chapter-link float-end" href="08-ethics.html" rel="next">
          Next: Ethics and the...
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i>
        </a>
      </div>
      <hr></nav><main id="main-content" class="main-content"><div class="container lesson-content">
        <h1>Neural Networks</h1>
        <p>Last updated on 2025-07-23 |

        <a href="https://github.com/jonathan-hartman/machine-learning-novice-sklearn/edit/main/episodes/07-neural-networks.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>



        <div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>

        

<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul><li>What are Neural Networks?</li>
<li>How can we classify images using a neural network?</li>
</ul></div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul><li>Understand the basic architecture of a perceptron.</li>
<li>Be able to create a perceptron to encode a simple function.</li>
<li>Understand that layers of perceptrons allow non-linear separable
problems to be solved.</li>
<li>Train a multi-layer perceptron using Scikit-Learn.</li>
<li>Evaluate the accuracy of a multi-layer perceptron using real input
data.</li>
<li>Understand that cross validation allows the entire data set to be
used in the training process.</li>
</ul></div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="neural-networks">Neural networks<a class="anchor" aria-label="anchor" href="#neural-networks"></a></h2>
<hr class="half-width"><p>Neural networks are a machine learning method inspired by how the
human brain works. They are particularly good at pattern recognition and
classification tasks, often using images as inputs. They are a
well-established machine learning technique, having been around since
the 1950s, but they’ve gone through several iterations to overcome
limitations in previous generations. Using state-of-the-art neural
networks is often referred to as ‘deep learning’.</p>
</section><section><h2 class="section-heading" id="perceptrons">Perceptrons<a class="anchor" aria-label="anchor" href="#perceptrons"></a></h2>
<hr class="half-width"><p>Perceptrons are the building blocks of neural networks. They are an
artificial version of a single neuron in the brain. They typically have
one or more inputs and a single output. Each input will be multiplied by
a weight and the value of all the weighted inputs are then summed
together. Finally, the summed value is put through an activation
function which decides if the neuron “fires” a signal. In some cases,
this activation function is simply a threshold step function which
outputs zero below a certain input and one above it. Other designs of
neurons use other activation functions, but typically they have an
output between zero and one and are still step-like in their nature.</p>
<figure><img src="fig/perceptron.svg" alt="A diagram of a perceptron, showing three inputs, leading to a summation unit, then a thresholding unit, and finally an output." class="figure mx-auto d-block"><div class="figcaption">A diagram of a perceptron</div>
</figure><div class="section level3">
<h3 id="coding-a-perceptron">Coding a perceptron<a class="anchor" aria-label="anchor" href="#coding-a-perceptron"></a></h3>
<p>Below is an example of a perceptron written as a Python function. The
function takes three parameters: <code>Inputs</code> is a list of input
values, <code>Weights</code> is a list of weight values and
<code>Threshold</code> is the activation threshold.</p>
<p>First we multiply each input by the corresponding weight. To do this
quickly and concisely, we will use the numpy multiply function which can
multiply each item in a list by a corresponding item in another
list.</p>
<p>We then take the sum of all the inputs multiplied by their weights.
Finally, if this value is less than the activation threshold, we output
zero, otherwise we output a one.</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="kw">def</span> perceptron(inputs, weights, threshold):</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a>    <span class="cf">assert</span> <span class="bu">len</span>(inputs) <span class="op">==</span> <span class="bu">len</span>(weights)</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a>    <span class="co"># multiply the inputs and weights</span></span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a>    values <span class="op">=</span> np.multiply(inputs,weights)</span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a>    <span class="co"># sum the results</span></span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a>    total <span class="op">=</span> <span class="bu">sum</span>(values)</span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a>    <span class="co"># decide if we should activate the perceptron</span></span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a>    <span class="cf">if</span> total <span class="op">&lt;</span> threshold:</span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a>        <span class="cf">return</span> <span class="dv">0</span></span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb1-16"><a href="#cb1-16" tabindex="-1"></a>        <span class="cf">return</span> <span class="dv">1</span></span></code></pre>
</div>
</div>
<div class="section level3">
<h3 id="computing-with-a-perceptron">Computing with a perceptron<a class="anchor" aria-label="anchor" href="#computing-with-a-perceptron"></a></h3>
<p>A single perceptron can perform basic linear classification problems
such as computing the logical AND, OR, and NOT functions.</p>
<p>OR</p>
<table class="table"><thead><tr class="header"><th>Input 1</th>
<th>Input 2</th>
<th>Output</th>
</tr></thead><tbody><tr class="odd"><td>0</td>
<td>0</td>
<td>0</td>
</tr><tr class="even"><td>0</td>
<td>1</td>
<td>1</td>
</tr><tr class="odd"><td>1</td>
<td>0</td>
<td>1</td>
</tr><tr class="even"><td>1</td>
<td>1</td>
<td>1</td>
</tr></tbody></table><p>AND</p>
<table class="table"><thead><tr class="header"><th>Input 1</th>
<th>Input 2</th>
<th>Output</th>
</tr></thead><tbody><tr class="odd"><td>0</td>
<td>0</td>
<td>0</td>
</tr><tr class="even"><td>0</td>
<td>1</td>
<td>0</td>
</tr><tr class="odd"><td>1</td>
<td>0</td>
<td>0</td>
</tr><tr class="even"><td>1</td>
<td>1</td>
<td>1</td>
</tr></tbody></table><p>NOT</p>
<table class="table"><thead><tr class="header"><th>Input 1</th>
<th>Output</th>
</tr></thead><tbody><tr class="odd"><td>0</td>
<td>1</td>
</tr><tr class="even"><td>1</td>
<td>0</td>
</tr></tbody></table><p>We can get a single perceptron to compute each of these functions</p>
<p>OR:</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a>inputs <span class="op">=</span> [[<span class="fl">0.0</span>,<span class="fl">0.0</span>],[<span class="fl">1.0</span>,<span class="fl">0.0</span>],[<span class="fl">0.0</span>,<span class="fl">1.0</span>],[<span class="fl">1.0</span>,<span class="fl">1.0</span>]]</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="cf">for</span> <span class="bu">input</span> <span class="kw">in</span> inputs:</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>    <span class="bu">print</span>(<span class="bu">input</span>,perceptron(<span class="bu">input</span>, [<span class="fl">0.5</span>,<span class="fl">0.5</span>], <span class="fl">0.5</span>))</span></code></pre>
</div>
<p>AND:</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a>inputs <span class="op">=</span> [[<span class="fl">0.0</span>,<span class="fl">0.0</span>],[<span class="fl">1.0</span>,<span class="fl">0.0</span>],[<span class="fl">0.0</span>,<span class="fl">1.0</span>],[<span class="fl">1.0</span>,<span class="fl">1.0</span>]]</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a><span class="cf">for</span> <span class="bu">input</span> <span class="kw">in</span> inputs:</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a>    <span class="bu">print</span>(<span class="bu">input</span>,perceptron(<span class="bu">input</span>, [<span class="fl">0.5</span>,<span class="fl">0.5</span>], <span class="fl">1.0</span>))</span></code></pre>
</div>
<p>NOT:</p>
<div id="callout1" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Callout</h3>
<div class="callout-content">
<p>The NOT function only has a single input. To make it work in the
perceptron we need to introduce a bias term which is always the same
value. In this example it is the second input. It has a weight of 1.0
while the weight on the real input is -1.0.</p>
</div>
</div>
</div>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a>inputs <span class="op">=</span> [[<span class="fl">0.0</span>,<span class="fl">1.0</span>],[<span class="fl">1.0</span>,<span class="fl">1.0</span>]]</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a><span class="cf">for</span> <span class="bu">input</span> <span class="kw">in</span> inputs:</span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>    <span class="bu">print</span>(<span class="bu">input</span>,perceptron(<span class="bu">input</span>, [<span class="op">-</span><span class="fl">1.0</span>,<span class="fl">1.0</span>], <span class="fl">1.0</span>))</span></code></pre>
</div>
<p>A perceptron can be trained to compute any function which has linear
separability. A simple training algorithm called the perceptron learning
algorithm can be used to do this and Scikit-Learn has its own
implementation of it. We are going to skip over the perceptron learning
algorithm and move straight onto more powerful techniques. If you want
to learn more about it see <a href="https://computing.dcu.ie/~humphrys/Notes/Neural/single.neural.html" class="external-link">this
page</a> from Dublin City University.</p>
</div>
<div class="section level3">
<h3 id="perceptron-limitations">Perceptron limitations<a class="anchor" aria-label="anchor" href="#perceptron-limitations"></a></h3>
<p>A single perceptron cannot solve any function that is not linearly
separable, meaning that we need to be able to divide the classes of
inputs and outputs with a straight line. A common example of this is the
XOR function shown below:</p>
<table class="table"><thead><tr class="header"><th>Input 1</th>
<th>Input 2</th>
<th>Output</th>
</tr></thead><tbody><tr class="odd"><td>0</td>
<td>0</td>
<td>0</td>
</tr><tr class="even"><td>0</td>
<td>1</td>
<td>1</td>
</tr><tr class="odd"><td>1</td>
<td>0</td>
<td>1</td>
</tr><tr class="even"><td>1</td>
<td>1</td>
<td>0</td>
</tr></tbody></table><p>(Make a graph of this)</p>
<p>This function outputs a zero when all its inputs are one or zero and
its not possible to separate with a straight line. This is known as
linear separability. When this limitation was discovered in the 1960s it
effectively halted development of neural networks for over a decade in a
period known as the “AI Winter”.</p>
</div>
</section><section><h2 class="section-heading" id="multi-layer-perceptrons">Multi-layer perceptrons<a class="anchor" aria-label="anchor" href="#multi-layer-perceptrons"></a></h2>
<hr class="half-width"><p>A single perceptron cannot be used to solve a non-linearly separable
function. For that, we need to use multiple perceptrons and typically
multiple layers of perceptrons. They are formed of networks of
artificial neurons which each take one or more inputs and typically have
a single output. The neurons are connected together in networks of 10s
to 1000s of neurons. Typically, networks are connected in layers with an
input layer, middle or hidden layer (or layers), and finally an output
layer.</p>
<figure><img src="fig/multilayer_perceptron.svg" alt="A diagram of a multi-layer perceptron, showing an input layer with 3 inputs, a hidden layer with 2 neurons, and an output layer with 3 outputs. The connections between the layers are shown." class="figure mx-auto d-block"><div class="figcaption">A multi-layer perceptron</div>
</figure><div class="section level3">
<h3 id="training-multi-layer-perceptrons">Training multi-layer perceptrons<a class="anchor" aria-label="anchor" href="#training-multi-layer-perceptrons"></a></h3>
<p>Multi-layer perceptrons need to be trained by showing them a set of
training data and measuring the error between the network’s predicted
output and the true value. Training takes an iterative approach that
improves the network a little each time a new training example is
presented. There are a number of training algorithms available for a
neural network today, but we are going to use one of the best
established and well known, the backpropagation algorithm. This
algorithm is called back propagation because it takes the error
calculated between an output of the network and the true value and takes
it back through the network to update the weights.</p>
<!--If you want to read more about back propagation, please see [this chapter](http://page.mi.fu-berlin.de/rojas/neural/chapter/K7.pdf) from the book "Neural Networks - A Systematic Introduction". THIS LINK IS BROKEN. -->
</div>
<div class="section level3">
<h3 id="multi-layer-perceptrons-in-scikit-learn">Multi-layer perceptrons in Scikit-Learn<a class="anchor" aria-label="anchor" href="#multi-layer-perceptrons-in-scikit-learn"></a></h3>
<p>We are going to build a multi-layer perceptron for recognising
handwriting from images. Scikit-Learn includes some example handwriting
data from the <a href="https://github.com/cvdfoundation/mnist" class="external-link">MNIST
data set</a>, which is a dataset containing 70,000 images of
hand-written digits. Each image is 28x28 pixels in size (784 pixels in
total) and is represented in grayscale with values between zero for
fully black and 255 for fully white. This means we will need 784
perceptrons in our input layer, each taking the input of one pixel and
10 perceptrons in our output layer to represent each digit we might
classify. If trained correctly, only the perceptron in the output layer
will “fire” to represent the contents of the image (but this is a
massive oversimplification!).</p>
<p>We can import this dataset from <code>sklearn.datasets</code> then
load it into memory by calling the <code>fetch_openml</code>
function.</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="im">import</span> sklearn.datasets <span class="im">as</span> skl_data</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>data, labels <span class="op">=</span> skl_data.fetch_openml(<span class="st">'mnist_784'</span>, version<span class="op">=</span><span class="dv">1</span>, return_X_y<span class="op">=</span><span class="va">True</span>)</span></code></pre>
</div>
<p>This creates two arrays of data, one called <code>data</code> which
contains the image data and the other <code>labels</code> that contains
the labels for those images which will tell us which digit is in the
image. A common convention is to call the data <code>X</code> and the
labels <code>y</code>.</p>
<p>As neural networks typically want to work with data that ranges
between 0 and 1.0 we need to normalise our data to this range. Python
has a shortcut which lets us divide the entire data array by 255 and
store the result, we can simply do:</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a>data <span class="op">=</span> data <span class="op">/</span> <span class="fl">255.0</span></span></code></pre>
</div>
<p>This is instead of writing a loop ourselves to divide every pixel by
255. Although the final result is the same and will take about the same
amount of computation (possibly a little less, it might do some clever
optimisations).</p>
<p>Now we need to initialise a neural network. Scikit-Learn has an
entire library for this (<code>sklearn.neural_network</code>) and the
<code>MLPClassifier</code> class handles multi-layer perceptrons. This
network takes a few parameters including the size of the hidden layer,
the maximum number of training iterations we’re going to allow, the
exact algorithm to use, whether or not we’d like verbose output about
what the training is doing, and the initial state of the random number
generator.</p>
<p>In this example we specify a multi-layer perceptron with 50 hidden
nodes, we allow a maximum of 50 iterations to train it, we turn on
verbose output to see what’s happening, and initialise the random state
to 1 so that we always get the same behaviour.</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="im">import</span> sklearn.neural_network <span class="im">as</span> skl_nn</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>mlp <span class="op">=</span> skl_nn.MLPClassifier(hidden_layer_sizes<span class="op">=</span>(<span class="dv">50</span>,), max_iter<span class="op">=</span><span class="dv">50</span>, verbose<span class="op">=</span><span class="dv">1</span>, random_state<span class="op">=</span><span class="dv">1</span>)</span></code></pre>
</div>
<p>We now have a neural network but we have not trained it yet. Before
training, we will split our dataset into two parts: a training set which
we will use to train the classifier and a test set which we will use to
see how well the training is working. By using different data for the
two, we can avoid ‘over-fitting’, which is the creation of models which
do not “generalise” or work with data other than their training
data.</p>
<p>Typically, the majority of the data will be used as training data
(70-90%), to help avoid overfitting. Let us see how big our dataset is
to decide how many samples we want to train with.</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a>data.shape</span></code></pre>
</div>
<p>This tells us we have 70,000 rows in the dataset. Let us take 90% of
the data for training and 10% for testing, so we will use the first
63,000 samples in the dataset as the training data and the last 7,000 as
the test data.</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a><span class="co"># Assuming `data` is your feature matrix and `labels` is your target vector</span></span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a>    data.values,        <span class="co"># Features</span></span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a>    labels.values,      <span class="co"># Labels</span></span>
<span id="cb9-7"><a href="#cb9-7" tabindex="-1"></a>    test_size<span class="op">=</span><span class="fl">0.1</span>,      <span class="co"># Reserve 10% of data for testing</span></span>
<span id="cb9-8"><a href="#cb9-8" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span>     <span class="co"># For reproducibility</span></span>
<span id="cb9-9"><a href="#cb9-9" tabindex="-1"></a>)</span>
<span id="cb9-10"><a href="#cb9-10" tabindex="-1"></a>X_train.shape</span></code></pre>
</div>
<p>Now lets train the network. This line will take about one minute to
run. We do this by calling the <code>fit</code> function inside the
<code>mlp</code> class instance. This needs two arguments: the data
itself, and the labels showing what class each item should be classified
to.</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a>mlp.fit(X_train, y_train)</span></code></pre>
</div>
<p>Finally, we will score the accuracy of our network against both the
original training data and the test data. If the training had converged
to the point where each iteration of training was not improving the
accuracy, then the accuracy of the training data should be 1.0
(100%).</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Training set score"</span>, mlp.score(X_train, y_train))</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Testing set score"</span>, mlp.score(X_test, y_test))</span></code></pre>
</div>
<p>Here is the complete program:</p>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a><span class="im">import</span> sklearn.datasets <span class="im">as</span> skl_data</span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a><span class="im">import</span> sklearn.neural_network <span class="im">as</span> skl_nn</span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a>data, labels <span class="op">=</span> skl_data.fetch_openml(<span class="st">'mnist_784'</span>, version<span class="op">=</span><span class="dv">1</span>, return_X_y<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb12-6"><a href="#cb12-6" tabindex="-1"></a>data <span class="op">=</span> data <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb12-7"><a href="#cb12-7" tabindex="-1"></a></span>
<span id="cb12-8"><a href="#cb12-8" tabindex="-1"></a></span>
<span id="cb12-9"><a href="#cb12-9" tabindex="-1"></a>mlp <span class="op">=</span> skl_nn.MLPClassifier(hidden_layer_sizes<span class="op">=</span>(<span class="dv">50</span>,), max_iter<span class="op">=</span><span class="dv">50</span>, verbose<span class="op">=</span><span class="dv">1</span>, random_state<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb12-10"><a href="#cb12-10" tabindex="-1"></a></span>
<span id="cb12-11"><a href="#cb12-11" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb12-12"><a href="#cb12-12" tabindex="-1"></a></span>
<span id="cb12-13"><a href="#cb12-13" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb12-14"><a href="#cb12-14" tabindex="-1"></a>    data.values,        <span class="co"># Features</span></span>
<span id="cb12-15"><a href="#cb12-15" tabindex="-1"></a>    labels.values,      <span class="co"># Labels</span></span>
<span id="cb12-16"><a href="#cb12-16" tabindex="-1"></a>    test_size<span class="op">=</span><span class="fl">0.1</span>,      <span class="co"># Reserve 10% of data for testing</span></span>
<span id="cb12-17"><a href="#cb12-17" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span>     <span class="co"># For reproducibility</span></span>
<span id="cb12-18"><a href="#cb12-18" tabindex="-1"></a>)</span>
<span id="cb12-19"><a href="#cb12-19" tabindex="-1"></a></span>
<span id="cb12-20"><a href="#cb12-20" tabindex="-1"></a>mlp.fit(X_train, y_train)</span>
<span id="cb12-21"><a href="#cb12-21" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Training set score"</span>, mlp.score(X_train, y_train))</span>
<span id="cb12-22"><a href="#cb12-22" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Testing set score"</span>, mlp.score(X_test, y_test))</span></code></pre>
</div>
</div>
<div class="section level3">
<h3 id="prediction-using-a-multi-layer-perceptron">Prediction using a multi-layer perceptron<a class="anchor" aria-label="anchor" href="#prediction-using-a-multi-layer-perceptron"></a></h3>
<p>Now that we have trained a multi-layer perceptron, we can give it
some input data and ask it to perform a prediction. In this case, our
input data is a 28x28 pixel image, which can also be represented as a
784-element list of data. The output will be a number between 0 and 9
telling us which digit the network thinks we have supplied. The
<code>predict</code> function in the <code>MLPClassifier</code> class
can be used to make a prediction. Lets use the first digit from our test
set as an example.</p>
<p>Before we can pass it to the predictor, we need to extract one of the
digits from the test set. We can use <code>iloc</code> on the dataframe
to get hold of the first element in the test set. In order to present it
to the predictor, we have to turn it into a numpy array which has the
dimensions of 1x784 instead of 28x28. We can then call the
<code>predict</code> function with this array as our parameter. This
will return an array of predictions (as it could have been given
multiple inputs), the first element of this will be the predicted digit.
You may get a warning stating “X does not have valid feature names”,
this is because we didn’t encode feature names into our X (digit images)
data.</p>
<div class="codewrapper sourceCode" id="cb13">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a>test_digit <span class="op">=</span> X_test[<span class="dv">0</span>].reshape(<span class="dv">1</span>,<span class="dv">784</span>) <span class="co"># current shape is (784,)</span></span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a>test_digit_prediction <span class="op">=</span> mlp.predict(test_digit)[<span class="dv">0</span>]</span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Predicted value"</span>,test_digit_prediction)</span></code></pre>
</div>
<p>We can now verify if the prediction is correct by looking at the
corresponding item in the <code>labels_test</code> array.</p>
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Actual value"</span>,y_test[<span class="dv">0</span>])</span></code></pre>
</div>
<p>This should be the same value which is being predicted.</p>
<div id="changing-the-learning-parameters" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div id="changing-the-learning-parameters" class="callout-inner">
<h3 class="callout-title">Changing the learning parameters</h3>
<div class="callout-content">
<p>There are several parameters which control the training of the data.
One of these is called the learning rate. Increasing this can reduce how
many learning iterations we need. But if this is too large you can end
up overshooting. Try tweaking this parameter by adding the parameter
<code>learning_rate_init</code> with a default value of 0.001. Try
increasing it to around 0.1.</p>
</div>
</div>
</div>
<div id="using-your-own-handwriting" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div id="using-your-own-handwriting" class="callout-inner">
<h3 class="callout-title">Using your own handwriting</h3>
<div class="callout-content">
<p>Create an image using Microsoft Paint, the GNU Image Manipulation
Project (GIMP) or <a href="https://jspaint.app/" class="external-link">jspaint</a>. The image
needs to be grayscale and 28 x 28 pixels.</p>
<p>Try to draw a digit (0-9) in the image and save it into your code
directory.</p>
<p>The code below loads the image (called digit.png, change to whatever
your file is called) using the OpenCV library. Some Anaconda
installations need this installed either through the package manager or
by running the command: <code>conda install -c conda-forge opencv</code>
from the anaconda terminal.</p>
<p>OpenCV assumes that images are 3 channel red, green, blue and we have
to convert to one channel grayscale with <code>cvtColor</code>.</p>
<p>We also need to normalise the image by dividing each pixel by
255.</p>
<p>To verify the image, we can plot it by using OpenCV’s
<code>imshow</code> function (we could also use Matplotlib’s
<code>matshow</code> function).</p>
<p>To check what digit it is, we can pass it into
<code>mlp.predict</code>, but we have to convert it from a 28x28 array
to a one dimensional 784-byte long array with the <code>reshape</code>
function.</p>
<p>Did it correctly classify your hand(mouse) writing? Try a few images.
If you have time try drawing images on a touch screen or taking a photo
of something you have really written by hand. Remember that you will
have to resize it to be 28x28 pixels.</p>
<pre><code>import cv2
import matplotlib.pyplot as plt
digit = cv2.imread("digit.png")
digit_gray = cv2.cvtColor(digit, cv2.COLOR_BGR2GRAY)
digit_norm = digit_gray/255.0
cv2.imshow("Normalised Digit",digit_norm)
print("Your digit is",mlp.predict(digit_norm.reshape(1,784)))</code></pre>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="measuring-neural-network-performance">Measuring neural network performance<a class="anchor" aria-label="anchor" href="#measuring-neural-network-performance"></a></h2>
<hr class="half-width"><p>We have now trained a neural network and tested prediction on a few
images. This might have given us a feel for how well our network is
performing, but it would be much more useful to have a more objective
measure. Since recognising digits is a classification problem, we can
measure how many predictions were correct in a set of test data. As we
already have a test set of data with 7,000 images we can use that and
see how many predictions the neural network has gotten right. We will
loop through every image in the test set, run it through our predictor
and compare the result with the label for that image. We will also keep
a tally of how many images we got right and see what percentage were
correct.</p>
<div class="codewrapper sourceCode" id="cb16">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a>correct<span class="op">=</span><span class="dv">0</span></span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" tabindex="-1"></a><span class="cf">for</span> idx, row <span class="kw">in</span> <span class="bu">enumerate</span>(data_test):</span>
<span id="cb16-4"><a href="#cb16-4" tabindex="-1"></a>    <span class="co"># image contains a tuple of the row number and image data</span></span>
<span id="cb16-5"><a href="#cb16-5" tabindex="-1"></a>    image <span class="op">=</span> row.reshape(<span class="dv">1</span>,<span class="dv">784</span>)</span>
<span id="cb16-6"><a href="#cb16-6" tabindex="-1"></a></span>
<span id="cb16-7"><a href="#cb16-7" tabindex="-1"></a>    prediction <span class="op">=</span> mlp.predict(image)[<span class="dv">0</span>]</span>
<span id="cb16-8"><a href="#cb16-8" tabindex="-1"></a>    actual <span class="op">=</span> labels_test[idx]</span>
<span id="cb16-9"><a href="#cb16-9" tabindex="-1"></a></span>
<span id="cb16-10"><a href="#cb16-10" tabindex="-1"></a>    <span class="cf">if</span> prediction <span class="op">==</span> actual:</span>
<span id="cb16-11"><a href="#cb16-11" tabindex="-1"></a>        correct <span class="op">=</span> correct <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb16-12"><a href="#cb16-12" tabindex="-1"></a></span>
<span id="cb16-13"><a href="#cb16-13" tabindex="-1"></a><span class="bu">print</span>((correct<span class="op">/</span><span class="bu">len</span>(data_test))<span class="op">*</span><span class="dv">100</span>)</span></code></pre>
</div>
<div class="section level3">
<h3 id="confusion-matrix">Confusion matrix<a class="anchor" aria-label="anchor" href="#confusion-matrix"></a></h3>
<p>We now know what percentage of images were correctly classified, but
we don’t know anything about the distribution of correct predictions
across our different classes (the digits 0 to 9 in this case). A more
powerful technique is known as a confusion matrix. Here we draw a grid
with each class along both the x and y axis. The x axis is the actual
number of items in each class and the y axis is the predicted number. In
a perfect classifier, there will be a diagonal line of values across the
grid moving from the top left to bottom right corresponding to the
number in each class, and all other cells will be zero. If any cell
outside of the diagonal is non-zero then it indicates a
miss-classification. Scikit-Learn has a function called
<code>confusion_matrix</code> in the <code>sklearn.metrics</code> class
which can display a confusion matrix for us. It will need two inputs:
arrays showing how many items were in each class for both the real data
and the classifications. We already have the real data in the
labels_test array, but we need to build it for the classifications by
classifying each image (in the same order as the real data) and storing
the result in another array.</p>
<div class="codewrapper sourceCode" id="cb17">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a><span class="co"># extract all test set predictions</span></span>
<span id="cb17-2"><a href="#cb17-2" tabindex="-1"></a>y_test_pred <span class="op">=</span> mlp.predict(X_test)</span>
<span id="cb17-3"><a href="#cb17-3" tabindex="-1"></a>y_test_pred</span></code></pre>
</div>
<p>The <code>ConfusionMatrixDisplay</code> class in the
<code>sklearn.metrics</code> package can create a graphical
representation of a confusion matrix with colour coding to highlight how
many items are in each cell. This colour coding can be useful when
working with very large numbers of classes.</p>
<div class="codewrapper sourceCode" id="cb18">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb18-2"><a href="#cb18-2" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> ConfusionMatrixDisplay</span>
<span id="cb18-3"><a href="#cb18-3" tabindex="-1"></a>ConfusionMatrixDisplay.from_predictions(y_test,y_test_pred)</span></code></pre>
</div>
</div>
</section><section><h2 class="section-heading" id="cross-validation">Cross-validation<a class="anchor" aria-label="anchor" href="#cross-validation"></a></h2>
<hr class="half-width"><p>Previously we split the data into training and test sets. But what if
the test set includes important features we want to train on that happen
to be missing in the training set? We are throwing away part of our data
to use it in the testing set.</p>
<p>Cross-validation runs the training/testing multiple times but splits
the data in a different way each time. This means all of the data gets
used both for training and testing. We can use multiple iterations of
training with different data in each set to eventually include the
entire dataset.</p>
<p>example list</p>
<p>[1,2,3,4,5,6,7,8]</p>
<p>train = 1,2,3,4,5,6 test = 7,8</p>
<p>train = 1,2,3,4,7,8 test = 5,6</p>
<p>train = 1,2,5,6,7,8 test = 3,4</p>
<p>train = 3,4,5,6,7,8 test = 1,2</p>
<p>(generate an image of this)</p>
<div class="section level3">
<h3 id="cross-validation-code-example">Cross-validation code example<a class="anchor" aria-label="anchor" href="#cross-validation-code-example"></a></h3>
<p>The <code>sklearn.model_selection</code> module provides support for
doing k-fold cross validation in Scikit-Learn. It can automatically
partition our data for cross validation.</p>
<p>Import this and call it <code>skl_msel</code></p>
<div class="codewrapper sourceCode" id="cb19">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" tabindex="-1"></a><span class="im">import</span> sklearn.model_selection <span class="im">as</span> skl_msel</span></code></pre>
</div>
<p>Now we can choose how many ways we would like to split our data
(three or four are common choices).</p>
<div class="codewrapper sourceCode" id="cb20">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" tabindex="-1"></a>kfold <span class="op">=</span> skl_msel.KFold(<span class="dv">4</span>)</span></code></pre>
</div>
<p>Now we can loop through our data and test on each combination. The
<code>kfold.split</code> function returns two variables and we will have
our for loop work through both of them. The train variable will contain
a list of which items (by index number) we are currently using to train
and the test one will contain the list of which items we are going to
test on.</p>
<div class="codewrapper sourceCode" id="cb21">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" tabindex="-1"></a><span class="cf">for</span> (train, test) <span class="kw">in</span> kfold.split(data):</span></code></pre>
</div>
<p>Now inside the loop, we can select the data with
<code>data_train = data.iloc[train]</code> and
<code>labels_train = labels.iloc[train]</code>. In some versions of
Python/Pandas/Scikit-Learn, you might be able to use
<code>data_train = data[train]</code> and
<code>labels_train = labels[train]</code>. This is a useful Python
shorthand which will use the list of indices from <code>train</code> to
select which items from <code>data</code> and <code>labels</code> we
use. We can repeat this process with the test set.</p>
<div class="codewrapper sourceCode" id="cb22">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" tabindex="-1"></a>    data_train <span class="op">=</span> data.iloc[train]</span>
<span id="cb22-2"><a href="#cb22-2" tabindex="-1"></a>    labels_train <span class="op">=</span> labels.iloc[train]</span>
<span id="cb22-3"><a href="#cb22-3" tabindex="-1"></a></span>
<span id="cb22-4"><a href="#cb22-4" tabindex="-1"></a>    data_test <span class="op">=</span> data.iloc[test]</span>
<span id="cb22-5"><a href="#cb22-5" tabindex="-1"></a>    labels_test <span class="op">=</span> labels.iloc[test]</span></code></pre>
</div>
<p>Finally, we need to train the classifier with the selected training
data and then score it against the test data. The scores for each set of
test data should be similar.</p>
<div class="codewrapper sourceCode" id="cb23">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" tabindex="-1"></a>    mlp.fit(data_train,labels_train)</span>
<span id="cb23-2"><a href="#cb23-2" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Testing set score"</span>, mlp.score(data_test, labels_test))</span></code></pre>
</div>
<p>Once we have established that the cross validation was ok, we can go
ahead and train using the entire dataset by doing
<code>mlp.fit(data,labels)</code>.</p>
<p>Here is the entire example program:</p>
<div class="codewrapper sourceCode" id="cb24">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb24-2"><a href="#cb24-2" tabindex="-1"></a><span class="im">import</span> sklearn.datasets <span class="im">as</span> skl_data</span>
<span id="cb24-3"><a href="#cb24-3" tabindex="-1"></a><span class="im">import</span> sklearn.neural_network <span class="im">as</span> skl_nn</span>
<span id="cb24-4"><a href="#cb24-4" tabindex="-1"></a><span class="im">import</span> sklearn.model_selection <span class="im">as</span> skl_msel</span>
<span id="cb24-5"><a href="#cb24-5" tabindex="-1"></a></span>
<span id="cb24-6"><a href="#cb24-6" tabindex="-1"></a>data, labels <span class="op">=</span> skl_data.fetch_openml(<span class="st">'mnist_784'</span>, version<span class="op">=</span><span class="dv">1</span>, return_X_y<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb24-7"><a href="#cb24-7" tabindex="-1"></a>data <span class="op">=</span> data <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb24-8"><a href="#cb24-8" tabindex="-1"></a></span>
<span id="cb24-9"><a href="#cb24-9" tabindex="-1"></a>mlp <span class="op">=</span> skl_nn.MLPClassifier(hidden_layer_sizes<span class="op">=</span>(<span class="dv">50</span>,), max_iter<span class="op">=</span><span class="dv">50</span>, random_state<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb24-10"><a href="#cb24-10" tabindex="-1"></a></span>
<span id="cb24-11"><a href="#cb24-11" tabindex="-1"></a>kfold <span class="op">=</span> skl_msel.KFold(<span class="dv">4</span>)</span>
<span id="cb24-12"><a href="#cb24-12" tabindex="-1"></a></span>
<span id="cb24-13"><a href="#cb24-13" tabindex="-1"></a><span class="cf">for</span> (train, test) <span class="kw">in</span> kfold.split(data):</span>
<span id="cb24-14"><a href="#cb24-14" tabindex="-1"></a>    data_train <span class="op">=</span> data.iloc[train]</span>
<span id="cb24-15"><a href="#cb24-15" tabindex="-1"></a>    labels_train <span class="op">=</span> labels.iloc[train]</span>
<span id="cb24-16"><a href="#cb24-16" tabindex="-1"></a></span>
<span id="cb24-17"><a href="#cb24-17" tabindex="-1"></a>    data_test <span class="op">=</span> data.iloc[test]</span>
<span id="cb24-18"><a href="#cb24-18" tabindex="-1"></a>    labels_test <span class="op">=</span> labels.iloc[test]</span>
<span id="cb24-19"><a href="#cb24-19" tabindex="-1"></a>    mlp.fit(data_train,labels_train)</span>
<span id="cb24-20"><a href="#cb24-20" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Training set score"</span>, mlp.score(data_train, labels_train))</span>
<span id="cb24-21"><a href="#cb24-21" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Testing set score"</span>, mlp.score(data_test, labels_test))</span>
<span id="cb24-22"><a href="#cb24-22" tabindex="-1"></a>mlp.fit(data,labels)</span></code></pre>
</div>
</div>
</section><section><h2 class="section-heading" id="deep-learning">Deep learning<a class="anchor" aria-label="anchor" href="#deep-learning"></a></h2>
<hr class="half-width"><p>Deep learning usually refers to newer neural network architectures
which use a special type of network known as a ‘convolutional network’.
Typically, these have many layers and thousands of neurons. They are
very good at tasks such as image recognition but take a long time to
train and run. They are often used with GPUs (Graphical Processing
Units) which are good at executing multiple operations simultaneously.
It is very common to use cloud computing or high performance computing
systems with multiple GPUs attached.</p>
<p>Scikit-Learn is not really setup for deep learning. We will have to
rely on other libraries. Common choices include Google’s TensorFlow,
Keras, (Py)Torch or Darknet. There is, however, an interface layer
between sklearn and tensorflow called skflow. A short example of using
this layer can be found at <a href="https://www.kdnuggets.com/2016/02/scikit-flow-easy-deep-learning-tensorflow-scikit-learn.html" class="external-link">https://www.kdnuggets.com/2016/02/scikit-flow-easy-deep-learning-tensorflow-scikit-learn.html</a>.</p>
<div class="section level3">
<h3 id="cloud-apis">Cloud APIs<a class="anchor" aria-label="anchor" href="#cloud-apis"></a></h3>
<p>Google, Microsoft, Amazon, and many other companys now have cloud
based Application Programming Interfaces (APIs) where you can upload an
image and have them return you the result. Most of these services rely
on a large pre-trained (and often proprietary) neural network.</p>
<div id="exercise-try-cloud-image-classificati" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div id="exercise-try-cloud-image-classificati" class="callout-inner">
<h3 class="callout-title">Exercise: Try cloud image classificati</h3>
<div class="callout-content">
<p>Take a photo with your phone camera or find an image online of a
common daily scene. Upload it to Google’s Vision AI at <a href="https://cloud.google.com/vision/" class="external-link uri">https://cloud.google.com/vision/</a> How many objects has it
correctly classified? How many did it incorrectly classify? Try the same
image with Microsoft’s Computer Vision API at <a href="https://azure.microsoft.com/en-gb/services/cognitive-services/computer-vision/" class="external-link uri">https://azure.microsoft.com/en-gb/services/cognitive-services/computer-vision/</a>
Does it do any better/worse than Google?</p>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points</h3>
<div class="callout-content">
<ul><li>Perceptrons are artificial neurons which build neural networks.</li>
<li>A perceptron takes multiple inputs, multiplies each by a weight
value and sums the weighted inputs. It then applies an activation
function to the sum.</li>
<li>A single perceptron can solve simple functions which are linearly
separable.</li>
<li>Multiple perceptrons can be combined to form a neural network which
can solve functions that aren’t linearly separable.</li>
<li>We can train a whole neural network with the back propagation
algorithm. Scikit-learn includes an implementation of this
algorithm.”</li>
<li>Training a neural network requires some training data to show the
network examples of what to learn</li>
<li>To validate our training we split the training data into a training
set and a test set.</li>
<li>To ensure the whole dataset can be used in training and testing we
can train multiple times with different subsets of the data acting as
training/testing data. This is called cross validation.</li>
<li>Deep learning neural networks are a very powerful modern machine
learning technique. Scikit-Learn does not support these but other
libraries like Tensorflow do.</li>
<li>Several companies now offer cloud APIs where we can train neural
networks on powerful computers.</li>
</ul></div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</div>
</section></div> <!-- / div.lesson-content -->
    </main><!-- / main#main-content.main-content --><nav class="bottom-pagination mx-md-4" aria-label="Previous and Next Chapter"><div class="d-block d-sm-block d-md-none">
        <a class="chapter-link" href="06-dimensionality-reduction.html"><i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>Previous</a>
        <a class="chapter-link float-end" href="08-ethics.html">Next<i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i></a>
      </div>
      <!-- content for large screens -->
      <div class="d-none d-sm-none d-md-block">
        <a class="chapter-link" href="06-dimensionality-reduction.html" rel="prev">
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>
          Previous: Unsupervised methods
        </a>
        <a class="chapter-link float-end" href="08-ethics.html" rel="next">
          Next: Ethics and the...
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i>
        </a>
      </div>
    </nav></div> <!-- / div.primary-content.col-xs-12 -->
<!-- END:   inst/pkgdown/templates/content-instructor.html-->

      </div><!--/div.row-->
      		<footer class="row footer mx-md-3"><hr><div class="col-md-6">
        <p>This lesson is subject to the <a href="CODE_OF_CONDUCT.html">Code of Conduct</a></p>
        <p>

        <a href="https://github.com/jonathan-hartman/machine-learning-novice-sklearn/edit/main/episodes/07-neural-networks.md" class="external-link">Edit on GitHub</a>

	
        | <a href="https://github.com/jonathan-hartman/machine-learning-novice-sklearn/blob/main/CONTRIBUTING.md" class="external-link">Contributing</a>
        | <a href="https://github.com/jonathan-hartman/machine-learning-novice-sklearn/" class="external-link">Source</a></p>
				<p><a href="https://github.com/jonathan-hartman/machine-learning-novice-sklearn/blob/main/CITATION.cff" class="external-link">Cite</a> | <a href="mailto:hartman@itc.rwth-aachen.de">Contact</a> | <a href="https://carpentries.org/about/" class="external-link">About</a></p>
			</div>
			<div class="col-md-6">

        <p>Materials licensed under <a href="LICENSE.html">CC-BY 4.0</a> by the authors</p>

        <p>Template licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/" class="external-link">CC-BY 4.0</a> by <a href="https://carpentries.org/" class="external-link">The Carpentries</a></p>
        <p>Built with <a href="https://github.com/carpentries/sandpaper/tree/0.16.12" class="external-link">sandpaper (0.16.12)</a>, <a href="https://github.com/carpentries/pegboard/tree/0.7.9" class="external-link">pegboard (0.7.9)</a>, and <a href="https://github.com/carpentries/varnish/tree/1.0.6" class="external-link">varnish (1.0.6)</a></p>
			</div>
		</footer></div> <!-- / div.container -->
	<div id="to-top">
		<a href="#top">
      <i class="search-icon" data-feather="arrow-up" role="img" aria-label="Back To Top"></i><br><!-- <span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top --><span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top
		</a>
	</div>
  <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "LearningResource",
  "@id": "https://jonathan-hartman.github.io/machine-learning-novice-sklearn/07-neural-networks.html",
  "inLanguage": "en",
  "dct:conformsTo": "https://bioschemas.org/profiles/LearningResource/1.0-RELEASE",
  "description": "A Carpentries Lesson teaching foundational data and coding skills to researchers worldwide",
  "keywords": "machine learning, python, sklearn, The Carpentries",
  "name": "Neural Networks",
  "creativeWorkStatus": "active",
  "url": "https://jonathan-hartman.github.io/machine-learning-novice-sklearn/07-neural-networks.html",
  "identifier": "https://jonathan-hartman.github.io/machine-learning-novice-sklearn/07-neural-networks.html",
  "dateCreated": "2025-07-23",
  "dateModified": "2025-07-23",
  "datePublished": "2025-07-29"
}

  </script><script>
		feather.replace();
	</script></body></html><!-- END:   inst/pkgdown/templates/layout.html-->

