<!DOCTYPE html>
<!-- START: inst/pkgdown/templates/layout.html --><!-- Generated by pkgdown: do not edit by hand --><html lang="en" data-bs-theme="auto"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><title>Introduction to Machine Learning with Scikit Learn: Ensemble methods</title><meta name="viewport" content="width=device-width, initial-scale=1"><script src="../assets/themetoggle.js"></script><link rel="stylesheet" type="text/css" href="../assets/styles.css"><script src="../assets/scripts.js" type="text/javascript"></script><!-- mathjax --><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      config: ["MMLorHTML.js"],
      jax: ["input/TeX","input/MathML","output/HTML-CSS","output/NativeMML", "output/PreviewHTML"],
      extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
      TeX: {
        extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
      },
      tex2jax: {
        inlineMath: [['\\(', '\\)']],
        displayMath: [ ['$$','$$'], ['\\[', '\\]'] ],
        processEscapes: true
      }
    });
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><!-- Responsive Favicon for The Carpentries --><link rel="apple-touch-icon" sizes="180x180" href="../favicons/incubator/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="../favicons/incubator/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="../favicons/incubator/favicon-16x16.png"><link rel="manifest" href="../favicons/incubator/site.webmanifest"><link rel="mask-icon" href="../favicons/incubator/safari-pinned-tab.svg" color="#5bbad5"><meta name="msapplication-TileColor" content="#da532c"><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"><meta name="theme-color" media="(prefers-color-scheme: dark)" content="black"></head><body>
    <header id="top" class="navbar navbar-expand-md top-nav incubator"><svg xmlns="http://www.w3.org/2000/svg" class="d-none"><symbol id="check2" viewbox="0 0 16 16"><path d="M13.854 3.646a.5.5 0 0 1 0 .708l-7 7a.5.5 0 0 1-.708 0l-3.5-3.5a.5.5 0 1 1 .708-.708L6.5 10.293l6.646-6.647a.5.5 0 0 1 .708 0z"></path></symbol><symbol id="circle-half" viewbox="0 0 16 16"><path d="M8 15A7 7 0 1 0 8 1v14zm0 1A8 8 0 1 1 8 0a8 8 0 0 1 0 16z"></path></symbol><symbol id="moon-stars-fill" viewbox="0 0 16 16"><path d="M6 .278a.768.768 0 0 1 .08.858 7.208 7.208 0 0 0-.878 3.46c0 4.021 3.278 7.277 7.318 7.277.527 0 1.04-.055 1.533-.16a.787.787 0 0 1 .81.316.733.733 0 0 1-.031.893A8.349 8.349 0 0 1 8.344 16C3.734 16 0 12.286 0 7.71 0 4.266 2.114 1.312 5.124.06A.752.752 0 0 1 6 .278z"></path><path d="M10.794 3.148a.217.217 0 0 1 .412 0l.387 1.162c.173.518.579.924 1.097 1.097l1.162.387a.217.217 0 0 1 0 .412l-1.162.387a1.734 1.734 0 0 0-1.097 1.097l-.387 1.162a.217.217 0 0 1-.412 0l-.387-1.162A1.734 1.734 0 0 0 9.31 6.593l-1.162-.387a.217.217 0 0 1 0-.412l1.162-.387a1.734 1.734 0 0 0 1.097-1.097l.387-1.162zM13.863.099a.145.145 0 0 1 .274 0l.258.774c.115.346.386.617.732.732l.774.258a.145.145 0 0 1 0 .274l-.774.258a1.156 1.156 0 0 0-.732.732l-.258.774a.145.145 0 0 1-.274 0l-.258-.774a1.156 1.156 0 0 0-.732-.732l-.774-.258a.145.145 0 0 1 0-.274l.774-.258c.346-.115.617-.386.732-.732L13.863.1z"></path></symbol><symbol id="sun-fill" viewbox="0 0 16 16"><path d="M8 12a4 4 0 1 0 0-8 4 4 0 0 0 0 8zM8 0a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 0zm0 13a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 13zm8-5a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2a.5.5 0 0 1 .5.5zM3 8a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2A.5.5 0 0 1 3 8zm10.657-5.657a.5.5 0 0 1 0 .707l-1.414 1.415a.5.5 0 1 1-.707-.708l1.414-1.414a.5.5 0 0 1 .707 0zm-9.193 9.193a.5.5 0 0 1 0 .707L3.05 13.657a.5.5 0 0 1-.707-.707l1.414-1.414a.5.5 0 0 1 .707 0zm9.193 2.121a.5.5 0 0 1-.707 0l-1.414-1.414a.5.5 0 0 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .707zM4.464 4.465a.5.5 0 0 1-.707 0L2.343 3.05a.5.5 0 1 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .708z"></path></symbol></svg><a class="visually-hidden-focusable skip-link" href="#main-content">Skip to main content</a>
  <div class="container-fluid top-nav-container">
    <div class="col-md-8">
      <div class="large-logo">
        <img id="incubator-logo" alt="Carpentries Incubator" src="../assets/images/incubator-logo.svg"><span class="badge text-bg-warning">
          <abbr title="This lesson is in the alpha phase, which means that it has been taught once and lesson authors are iterating on feedback.">
            <a href="https://docs.carpentries.org/resources/curriculum/lesson-life-cycle.html" class="external-link alert-link">
              <i aria-hidden="true" class="icon" data-feather="alert-triangle" style="border-radius: 5px"></i>
              Alpha
            </a>
            <span class="visually-hidden">This lesson is in the alpha phase, which means that it has been taught once and lesson authors are iterating on feedback.</span>
          </abbr>
        </span>

      </div>
    </div>
    <div class="selector-container">
      <div id="theme-selector">
        <li class="nav-item dropdown" id="theme-button-list">
          <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
            <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="bd-theme-text"><li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                Light
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                Dark
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                Auto
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
          </ul></li>
      </div>

      <div class="dropdown" id="instructor-dropdown">
        <button class="btn btn-secondary dropdown-toggle bordered-button" type="button" id="dropdownMenu1" data-bs-toggle="dropdown" aria-expanded="false">
          <i aria-hidden="true" class="icon" data-feather="eye"></i> Instructor View <i data-feather="chevron-down"></i>
        </button>
        <ul class="dropdown-menu" aria-labelledby="dropdownMenu1"><li><button class="dropdown-item" type="button" onclick="window.location.href='../04-ensemble-methods.html';">Learner View</button></li>
        </ul></div>
    </div>
  </div>
  <hr></header><nav class="navbar navbar-expand-xl bottom-nav incubator" aria-label="Main Navigation"><div class="container-fluid nav-container">
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle Navigation">
      <span class="navbar-toggler-icon"></span>
      <span class="menu-title">Menu</span>
    </button>
    <div class="nav-logo">
      <img class="small-logo" alt="Carpentries Incubator" src="../assets/images/incubator-logo-sm.svg"></div>
    <div class="lesson-title-md">
      Introduction to Machine Learning with Scikit Learn
    </div>
    <div class="search-icon-sm">
      <!-- TODO: do not show until we have search
        <i role="img" aria-label="Search the All In One page" data-feather="search"></i>
      -->
    </div>
    <div class="desktop-nav">
      <ul class="navbar-nav me-auto mb-2 mb-lg-0"><li class="nav-item">
          <span class="lesson-title">
            Introduction to Machine Learning with Scikit Learn
          </span>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/key-points.html">Key Points</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/instructor-notes.html">Instructor Notes</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/images.html">Extract All Images</a>
        </li>
        <li class="nav-item dropdown">
          <button class="nav-link dropdown-toggle" id="navbarDropdown" data-bs-toggle="dropdown" aria-expanded="false">
            More <i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu" aria-labelledby="navbarDropdown"><li><a class="dropdown-item" href="guide.html">Instructor Notes</a></li><hr><li><a class="dropdown-item" href="reference.html">Reference</a></li>
          </ul></li>
      </ul></div>
    <!--
    <form class="d-flex col-md-2 search-form">
      <fieldset disabled>
      <input class="form-control me-2 searchbox" type="search" placeholder="" aria-label="">
        <button class="btn btn-outline-success tablet-search-button"  type="submit">
          <i class="search-icon" data-feather="search" role="img" aria-label="Search the All In One page"></i>
        </button>
      </fieldset>
    </form>
    -->
    <a id="search-button" class="btn btn-primary" href="../instructor/aio.html" role="button" aria-label="Search the All In One page">Search the All In One page</a>
  </div><!--/div.container-fluid -->
</nav><div class="col-md-12 mobile-title">
  Introduction to Machine Learning with Scikit Learn
</div>

<aside class="col-md-12 lesson-progress"><div style="width: 41%" class="percentage">
    41%
  </div>
  <div class="progress incubator">
    <div class="progress-bar incubator" role="progressbar" style="width: 41%" aria-valuenow="41" aria-label="Lesson Progress" aria-valuemin="0" aria-valuemax="100">
    </div>
  </div>
</aside><div class="container">
      <div class="row">
        <!-- START: inst/pkgdown/templates/navbar.html -->
<div id="sidebar-col" class="col-lg-4">
  <div id="sidebar" class="sidebar">
      <nav aria-labelledby="flush-headingEleven"><button role="button" aria-label="close menu" alt="close menu" aria-expanded="true" aria-controls="sidebar" class="collapse-toggle" data-collapse="Collapse " data-episodes="Episodes ">
          <i class="search-icon" data-feather="x" role="img"></i>
        </button>
        <div class="sidebar-inner">
          <div class="row mobile-row" id="theme-row-mobile">
            <div class="col" id="theme-selector">
              <li class="nav-item dropdown" id="theme-button-list">
                <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
                  <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><span class="d-lg-none ms-1" id="bd-theme-text">Toggle Theme</span>
                </button>
                <ul class="dropdown-menu dropdown-menu-right" aria-labelledby="bd-theme-text"><li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                      Light
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                      Dark
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                      <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                      Auto
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                </ul></li>
            </div>
          </div>
          <div class="row mobile-row">
            <div class="col">
              <div class="sidenav-view-selector">
                <div class="accordion accordion-flush" id="accordionFlush9">
                  <div class="accordion-item">
                    <h2 class="accordion-header" id="flush-headingNine">
                      <button class="accordion-button collapsed" id="instructor" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseNine" aria-expanded="false" aria-controls="flush-collapseNine">
                        <i id="eye" aria-hidden="true" class="icon" data-feather="eye"></i> Instructor View
                      </button>
                    </h2>
                    <div id="flush-collapseNine" class="accordion-collapse collapse" aria-labelledby="flush-headingNine" data-bs-parent="#accordionFlush2">
                      <div class="accordion-body">
                        <a href="../04-ensemble-methods.html">Learner View</a>
                      </div>
                    </div>
                  </div><!--/div.accordion-item-->
                </div><!--/div.accordion-flush-->
              </div><!--div.sidenav-view-selector -->
            </div><!--/div.col -->

            <hr></div><!--/div.mobile-row -->

          <div class="accordion accordion-flush" id="accordionFlush11">
            <div class="accordion-item">

              <button id="chapters" class="accordion-button show" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseEleven" aria-expanded="false" aria-controls="flush-collapseEleven">
                <h2 class="accordion-header chapters" id="flush-headingEleven">
                  EPISODES
                </h2>
              </button>
              <div id="flush-collapseEleven" class="accordion-collapse show collapse" aria-labelledby="flush-headingEleven" data-bs-parent="#accordionFlush11">

                <div class="accordion-body">
                  <div class="accordion accordion-flush" id="accordionFlush1">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading1">
        <a href="index.html">Summary and Schedule</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush2">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading2">
        <a href="01-introduction.html">1. Introduction</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush3">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading3">
        <a href="02-regression.html">2. Supervised methods - Regression</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush4">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading4">
        <a href="03-classification.html">3. Supervised methods - Classification</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlushcurrent">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-headingcurrent">
      <button class="accordion-button" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapsecurrent" aria-expanded="true" aria-controls="flush-collapsecurrent">
        <span class="visually-hidden">Current Chapter</span>
        <span class="current-chapter">
        4. Ensemble methods
        </span>
      </button>
    </div><!--/div.accordion-header-->

    <div id="flush-collapsecurrent" class="accordion-collapse collapse show" aria-labelledby="flush-headingcurrent" data-bs-parent="#accordionFlushcurrent">
      <div class="accordion-body">
        <ul><li><a href="#ensemble-methods">Ensemble methods</a></li>
<li><a href="#using-bagging-random-forests-for-a-classification-problem">Using Bagging (Random Forests) for a classification problem</a></li>
<li><a href="#stacking-a-regression-problem">Stacking a regression problem</a></li>
        </ul></div><!--/div.accordion-body-->
    </div><!--/div.accordion-collapse-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush6">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading6">
        <a href="05-clustering.html">5. Unsupervised methods - Clustering</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush7">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading7">
        <a href="06-dimensionality-reduction.html">6. Unsupervised methods - Dimensionality reduction</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush8">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading8">
        <a href="07-neural-networks.html">7. Neural Networks</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush9">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading9">
        <a href="08-ethics.html">8. Ethics and the Implications of Machine Learning</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush10">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading10">
        <a href="09-learn-more.html">9. Find out more</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

                </div>
              </div>
            </div>

            <hr class="half-width"><div class="accordion accordion-flush lesson-resources" id="accordionFlush12">
              <div class="accordion-item">
                <h2 class="accordion-header" id="flush-headingTwelve">
                  <button class="accordion-button collapsed" id="lesson-resources" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseTwelve" aria-expanded="false" aria-controls="flush-collapseTwelve">
                    RESOURCES
                  </button>
                </h2>
                <div id="flush-collapseTwelve" class="accordion-collapse collapse" aria-labelledby="flush-headingTwelve" data-bs-parent="#accordionFlush12">
                  <div class="accordion-body">
                    <ul><li>
                        <a href="../instructor/key-points.html">Key Points</a>
                      </li>
                      <li>
                        <a href="../instructor/instructor-notes.html">Instructor Notes</a>
                      </li>
                      <li>
                        <a href="../instructor/images.html">Extract All Images</a>
                      </li>
                      <li><a href="guide.html">Instructor Notes</a></li><hr><li><a class="dropdown-item" href="reference.html">Reference</a></li>
                    </ul></div>
                </div>
              </div>
            </div>
            <hr class="half-width lesson-resources"><a href="../instructor/aio.html">See all in one page</a>


            <hr class="d-none d-sm-block d-md-none"><div class="d-grid gap-1">

            </div>
          </div><!-- /div.accordion -->
        </div><!-- /div.sidebar-inner -->
      </nav></div><!-- /div.sidebar -->
  </div><!-- /div.sidebar-col -->
<!-- END:   inst/pkgdown/templates/navbar.html-->

        <!-- START: inst/pkgdown/templates/content-instructor.html -->
  <div class="col-xl-8 col-lg-12 primary-content">
    <nav class="lesson-content mx-md-4" aria-label="Previous and Next Chapter"><!-- content for small screens --><div class="d-block d-sm-block d-md-none">
        <a class="chapter-link" href="../instructor/03-classification.html"><i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>Previous</a>
        <a class="chapter-link float-end" href="../instructor/05-clustering.html">Next<i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i></a>
      </div>
      <!-- content for large screens -->
      <div class="d-none d-sm-none d-md-block">
        <a class="chapter-link" href="../instructor/03-classification.html" rel="prev">
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>
          Previous: Supervised methods -
        </a>
        <a class="chapter-link float-end" href="../instructor/05-clustering.html" rel="next">
          Next: Unsupervised methods...
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i>
        </a>
      </div>
      <hr></nav><main id="main-content" class="main-content"><div class="container lesson-content">
        <h1>Ensemble methods</h1>
        <p>Last updated on 2025-07-23 |

        <a href="https://github.com/jonathan-hartman/machine-learning-novice-sklearn/edit/main/episodes/04-ensemble-methods.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>



        <p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 120 minutes</p>

        <div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>

        

<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul><li>What are ensemble methods?</li>
<li>What are random forests?</li>
<li>How can we stack estimators in sci-kit learn?</li>
</ul></div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul><li>Learn about applying ensemble methods in scikit-learn.</li>
<li>Understand why ensemble methods are useful.</li>
</ul></div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="ensemble-methods">Ensemble methods<a class="anchor" aria-label="anchor" href="#ensemble-methods"></a></h2>
<hr class="half-width"><p>What’s better than one decision tree? Perhaps two? or three? How
about enough trees to make up a forest? Ensemble methods bundle
individual models together and use each of their outputs to contribute
towards a final consensus for a given problem. Ensemble methods are
based on the mantra that the whole is greater than the sum of the
parts.</p>
<p>Thinking back to the classification episode with decision trees we
quickly stumbled into the problem of overfitting our training data. If
we combine predictions from a series of over/under fitting estimators
then we can often produce a better final prediction than using a single
reliable model - in the same way that humans often hear multiple
opinions on a scenario before deciding a final outcome. Decision trees
and regressions are often very sensitive to training outliers and so are
well suited to be a part of an ensemble.</p>
<p>Ensemble methods are used for a variety of applciations including,
but not limited to, search systems and object detection. We can use any
model/estimator available in sci-kit learn to create an ensemble. There
are three main methods to create ensembles approaches:</p>
<ul><li>Stacking</li>
<li>Bagging</li>
<li>Boosting</li>
</ul><p>Let’s explore them in a bit more depth.</p>
<div class="section level3">
<h3 id="stacking">Stacking<a class="anchor" aria-label="anchor" href="#stacking"></a></h3>
<p>This is where we train a series of different models/estimators on the
same input data in parallel. We then take the output of each model and
pass them into a final decision algorithm/model that makes the final
prediction.</p>
<p>If we trained the same model multiple times on the same data we would
expect very similar answers, and so the emphasis with stacking is to
choose different models that can be used to build up a reliable
concensus. Regression is then typically a good choice for the final
decision-making model.</p>
<figure><img src="../fig/stacking.jpeg" alt="A diagram showing how stacking works. It shows three different models being trained on the same data, and then their outputs being combined in a final model to make a prediction." class="figure mx-auto d-block"><div class="figcaption">Stacking</div>
</figure><p><a href="https://vas3k.com/blog/machine_learning/" class="external-link">Image from Vasily
Zubarev via their blog</a></p>
</div>
<div class="section level3">
<h3 id="bagging-a-k-a-bootstrap-aggregating">Bagging (a.k.a <a href="https://en.wikipedia.org/wiki/Bootstrap_aggregating" class="external-link">Bootstrap
AGGregatING</a> )<a class="anchor" aria-label="anchor" href="#bagging-a-k-a-bootstrap-aggregating"></a></h3>
<p>This is where we use the same model/estimator and fit it on different
subsets of the training data. We can then average the results from each
model to produce a final prediction. The subsets are random and may even
repeat themselves.</p>
<p>The most common example is known as the Random Forest algorithm,
which we’ll take a look at later on. Random Forests are typically used
as a faster, computationally cheaper alternative to Neural Networks,
which is ideal for real-time applications like camera face detection
prompts.</p>
<figure><img src="../fig/bagging.jpeg" alt="A diagram showing how bagging works. It shows the same model being trained on different subsets of the data, and then their outputs being averaged to make a prediction." class="figure mx-auto d-block"><div class="figcaption">Stacking</div>
</figure><p><a href="https://vas3k.com/blog/machine_learning/" class="external-link">Image from Vasily
Zubarev via their blog</a></p>
</div>
<div class="section level3">
<h3 id="boosting">Boosting<a class="anchor" aria-label="anchor" href="#boosting"></a></h3>
<p>This is where we train a single type of Model/estimator on an initial
dataset, test it’s accuracy, and then subsequently train the same type
of models on poorly predicted samples i.e. each new model pays most
attention to data that were incorrectly predicted by the last one.</p>
<p>Just like for bagging, boosting is trained mostly on subsets, however
in this case these subsets are not randomly generated but are instead
built using poorly estimated predictions. Boosting can produce some very
high accuracies by learning from it’s mistakes, but due to the iterative
nature of these improvements it doesn’t parallelize well unlike the
other ensemble methods. Despite this it can still be a faster, and
computationally cheaper alternative to Neural Networks.</p>
<figure><img src="../fig/boosting.jpeg" alt="A diagram showing how boosting works. It shows the same model being trained on the same data, but with each iteration focusing on the samples that were poorly predicted by the previous iteration." class="figure mx-auto d-block"><div class="figcaption">Stacking</div>
</figure><p><a href="https://vas3k.com/blog/machine_learning/" class="external-link">Image from Vasily
Zubarev via their blog</a></p>
</div>
<div class="section level3">
<h3 id="ensemble-summary">Ensemble summary<a class="anchor" aria-label="anchor" href="#ensemble-summary"></a></h3>
<p>Machine learning jargon can often be hard to remember, so here is a
quick summary of the 3 ensemble methods:</p>
<ul><li>Stacking - same dataset, different models, trained in parallel</li>
<li>Bagging - different subsets, same models, trained in parallel</li>
<li>Boosting - subsets of bad estimates, same models, trained in
series</li>
</ul></div>
</section><section><h2 class="section-heading" id="using-bagging-random-forests-for-a-classification-problem">Using Bagging (Random Forests) for a classification problem<a class="anchor" aria-label="anchor" href="#using-bagging-random-forests-for-a-classification-problem"></a></h2>
<hr class="half-width"><p>In this session we’ll take another look at the penguins data and
applying one of the most common bagging approaches, random forests, to
try and solve our species classification problem. First we’ll load in
the dataset and define a train and test split.</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="co"># import libraries</span></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a><span class="co"># load penguins data</span></span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a>penguins <span class="op">=</span> sns.load_dataset(<span class="st">'penguins'</span>)</span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a><span class="co"># prepare and define our data and targets</span></span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a>feature_names <span class="op">=</span> [<span class="st">'bill_length_mm'</span>, <span class="st">'bill_depth_mm'</span>, <span class="st">'flipper_length_mm'</span>, <span class="st">'body_mass_g'</span>]</span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a>penguins.dropna(subset<span class="op">=</span>feature_names, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a>species_names <span class="op">=</span> penguins[<span class="st">'species'</span>].unique()</span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" tabindex="-1"></a>X <span class="op">=</span> penguins[feature_names]</span>
<span id="cb1-17"><a href="#cb1-17" tabindex="-1"></a>y <span class="op">=</span> penguins.species</span>
<span id="cb1-18"><a href="#cb1-18" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" tabindex="-1"></a><span class="co"># Split data in training and test set</span></span>
<span id="cb1-20"><a href="#cb1-20" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb1-21"><a href="#cb1-21" tabindex="-1"></a></span>
<span id="cb1-22"><a href="#cb1-22" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"train size:"</span>, X_train.shape)</span>
<span id="cb1-23"><a href="#cb1-23" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"test size"</span>, X_test.shape)</span></code></pre>
</div>
<p>We’ll now take a look how we can use ensemble methods to perform a
classification task such as identifying penguin species! We’re going to
use a Random forest classifier available in scikit-learn which is a
widely used example of a bagging approach.</p>
<p>Random forests are built on decision trees and can provide another
way to address over-fitting. Rather than classifying based on one single
decision tree (which could overfit the data), an average of results of
many trees can be derived for more robust/accurate estimates compared
against single trees used in the ensemble.</p>
<figure><img src="../fig/randomforest.png" alt="A diagram showing how a random forest works. It shows multiple decision trees being trained on different subsets of the data, and then their outputs being combined to make a prediction." class="figure mx-auto d-block"><div class="figcaption">Random Forests</div>
</figure><p><a href="https://commons.wikimedia.org/wiki/File:Random_forest_diagram_complete.png" class="external-link">Image
from Venkatak Jagannath</a></p>
<p>We can now define a random forest estimator and train it using the
penguin training data. We have a similar set of attritbutes to the
DecisionTreeClassifier but with an extra parameter called n_estimators
which is the number of trees in the forest.</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> plot_tree</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a><span class="co"># Define our model</span></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a><span class="co"># extra parameter called n_estimators which is number of trees in the forest</span></span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a><span class="co"># a leaf is a class label at the end of the decision tree</span></span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a>forest <span class="op">=</span> RandomForestClassifier(n_estimators<span class="op">=</span><span class="dv">100</span>, max_depth<span class="op">=</span><span class="dv">7</span>, min_samples_leaf<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a><span class="co"># train our model</span></span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a>forest.fit(X_train, y_train)</span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a></span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a><span class="co"># Score our model</span></span>
<span id="cb2-13"><a href="#cb2-13" tabindex="-1"></a><span class="bu">print</span>(forest.score(X_test, y_test))</span></code></pre>
</div>
<p>You might notice that we have a different value (hopefully increased)
compared with the decision tree classifier used above on the same
training data. Lets plot the first 5 trees in the forest to get an idea
of how this model differs from a single decision tree.</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(nrows<span class="op">=</span><span class="dv">1</span>, ncols<span class="op">=</span><span class="dv">5</span> ,figsize<span class="op">=</span>(<span class="dv">12</span>,<span class="dv">6</span>))</span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a><span class="co"># plot first 5 trees in forest</span></span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a><span class="cf">for</span> index <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="dv">5</span>):</span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a>    plot_tree(forest.estimators_[index],</span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a>        class_names<span class="op">=</span>species_names,</span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a>        feature_names<span class="op">=</span>feature_names,</span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a>        filled<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a>        ax<span class="op">=</span>axes[index])</span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a></span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a>    axes[index].set_title(<span class="ss">f'Tree: </span><span class="sc">{</span>index<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb3-14"><a href="#cb3-14" tabindex="-1"></a></span>
<span id="cb3-15"><a href="#cb3-15" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<figure><img src="../fig/rf_5_trees.png" alt="A figure showing the first 5 trees in a random forest model. Each tree is a decision tree with different splits based on the penguin features, and each tree has a different structure and depth." class="figure mx-auto d-block"><div class="figcaption">random forest trees</div>
</figure><p>We can see the first 5 (of 100) trees that were fitted as part of the
forest.</p>
<p>If we train the random forest estimator using the same two parameters
used to plot the classification space for the decision tree classifier
what do we think the plot will look like?</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="co"># lets train a random forest for only two features (body mass and bill length)</span></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a><span class="im">from</span> sklearn.inspection <span class="im">import</span> DecisionBoundaryDisplay</span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>f1 <span class="op">=</span> feature_names[<span class="dv">0</span>]</span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a>f2 <span class="op">=</span> feature_names[<span class="dv">3</span>]</span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a><span class="co"># plot classification space for body mass and bill length with random forest</span></span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a>forest_2d <span class="op">=</span> RandomForestClassifier(n_estimators<span class="op">=</span><span class="dv">100</span>, max_depth<span class="op">=</span><span class="dv">7</span>, min_samples_leaf<span class="op">=</span><span class="dv">1</span>, random_state<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a>forest_2d.fit(X_train[[f1, f2]], y_train)</span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" tabindex="-1"></a><span class="co"># Lets plot the decision boundaries made by the model for the two trained features</span></span>
<span id="cb4-11"><a href="#cb4-11" tabindex="-1"></a>d <span class="op">=</span> DecisionBoundaryDisplay.from_estimator(forest_2d, X_train[[f1, f2]])</span>
<span id="cb4-12"><a href="#cb4-12" tabindex="-1"></a></span>
<span id="cb4-13"><a href="#cb4-13" tabindex="-1"></a>sns.scatterplot(X_train, x<span class="op">=</span>f1, y<span class="op">=</span>f2, hue<span class="op">=</span>y_train, palette<span class="op">=</span><span class="st">"husl"</span>)</span>
<span id="cb4-14"><a href="#cb4-14" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<figure><img src="../fig/EM_rf_clf_space.png" alt="A scatter plot of the penguin dataset, showing body mass on the x-axis and bill length on the y-axis. The points are coloured by species. The random forest classifier is shown as colored regions, with the boundaries between the regions being orthogonal lines. The regions are generally aligned with the species clusters, but there are still several misclassifications and a complicated decision space." class="figure mx-auto d-block"><div class="figcaption">random forest clf space</div>
</figure><p>There is still some overfitting indicated by the regions that contain
only single points but using the same hyper-parameter settings used to
fit the decision tree classifier, we can see that overfitting is
reduced.</p>
</section><section><h2 class="section-heading" id="stacking-a-regression-problem">Stacking a regression problem<a class="anchor" aria-label="anchor" href="#stacking-a-regression-problem"></a></h2>
<hr class="half-width"><p>We’ve had a look at a bagging approach, but we’ll now take a look at
a stacking approach and apply it to a regression problem. We’ll also
introduce a new dataset to play around with.</p>
<div class="section level3">
<h3 id="california-house-price-prediction">California house price prediction<a class="anchor" aria-label="anchor" href="#california-house-price-prediction"></a></h3>
<p>The California housing dataset for regression problems contains 8
training features such as, Median Income, House Age, Average Rooms,
Average Bedrooms etc. for 20,640 properties. The target variable is the
median house value for those 20,640 properties, note that all prices are
in units of $100,000. This toy dataset is available as part of the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html" class="external-link">scikit
learn library</a>. We’ll start by loading the dataset to very briefly
inspect the attributes by printing them out.</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="im">import</span> sklearn</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> fetch_california_housing</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a><span class="co"># load the dataset</span></span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>X, y <span class="op">=</span> fetch_california_housing(return_X_y<span class="op">=</span><span class="va">True</span>, as_frame<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a></span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a><span class="co">## All price variables are in units of $100,000</span></span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a><span class="bu">print</span>(X.shape)</span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a><span class="bu">print</span>(X.head())</span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a></span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Housing price as the target: "</span>)</span>
<span id="cb5-12"><a href="#cb5-12" tabindex="-1"></a></span>
<span id="cb5-13"><a href="#cb5-13" tabindex="-1"></a><span class="co">## Target is in units of $100,000</span></span>
<span id="cb5-14"><a href="#cb5-14" tabindex="-1"></a><span class="bu">print</span>(y.head())</span>
<span id="cb5-15"><a href="#cb5-15" tabindex="-1"></a><span class="bu">print</span>(y.shape)</span></code></pre>
</div>
<p>For the the purposes of learning how to create and use ensemble
methods and since it is a toy dataset, we will blindly use this dataset
without inspecting it, cleaning or pre-processing it further.</p>
<div id="exercise-investigate-and-visualise-the-dataset" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div id="exercise-investigate-and-visualise-the-dataset" class="callout-inner">
<h3 class="callout-title">Exercise: Investigate and visualise the dataset</h3>
<div class="callout-content">
<p>For this episode we simply want to learn how to build and use an
Ensemble rather than actually solve a regression problem. To build up
your skills as an ML practitioner, investigate and visualise this
dataset. What can you say about the dataset itself, and what can you
summarise about about any potential relationships or prediction
problems?</p>
</div>
</div>
</div>
<p>Lets start by splitting the dataset into training and testing
subsets:</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="co"># split into train and test sets, We are selecting an 80%-20% train-test split.</span></span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'train size: </span><span class="sc">{</span>X_train<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'test size: </span><span class="sc">{</span>X_test<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">'</span>)</span></code></pre>
</div>
<p>Lets stack a series of regression models. In the same way the
RandomForest classifier derives a results from a series of trees, we
will combine the results from a series of different models in our stack.
This is done using what’s called an ensemble meta-estimator called a
VotingRegressor.</p>
<p>We’ll apply a Voting regressor to a random forest, gradient boosting
and linear regressor.</p>
<p>Lets stack a series of regression models. In the same way the
RandomForest classifier derives a results from a series of trees, we
will combine the results from a series of different models in our stack.
This is done using what’s called an ensemble meta-estimator called a
VotingRegressor.</p>
<p>We’ll apply a Voting regressor to a random forest, gradient boosting
and linear regressor.</p>
<div id="but-wait-arent-random-forestsdecision-tree-for-classification-problems" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="but-wait-arent-random-forestsdecision-tree-for-classification-problems" class="callout-inner">
<h3 class="callout-title">But wait, aren’t random forests/decision tree for classification problems?</h3>
<div class="callout-content">
<p>Yes they are, but quite often in machine learning various models can
be used to solve both regression and classification problems. Decision
trees in particular can be used to “predict” specific numerical values
instead of categories, essentially by binning a group of values into a
single value. This works well for periodic/repeating numerical data.
These trees are extremely sensitive to the data they are trained on,
which makes them a very good model to use as a Random Forest.</p>
</div>
</div>
</div>
<div id="but-wait-again-isnt-a-random-forest-and-a-gradient-boosting-model-an-ensemble-method-instead-of-a-regression-model" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="but-wait-again-isnt-a-random-forest-and-a-gradient-boosting-model-an-ensemble-method-instead-of-a-regression-model" class="callout-inner">
<h3 class="callout-title">But wait again, isn’t a random forest (and a gradient boosting model) an ensemble method instead of a regression
model?</h3>
<div class="callout-content">
<p>Yes they are, but they can be thought of as one big complex model
used like any other model. The awesome thing about ensemble methods, and
the generalisation of Scikit-Learn models, is that you can put an
ensemble in an ensemble!</p>
</div>
</div>
</div>
<p>A VotingRegressor can train several base estimators on the whole
dataset, and it can take the average of the individual predictions to
form a final prediction.</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> (</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>    GradientBoostingRegressor,</span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a>    RandomForestRegressor,</span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a>    VotingRegressor,</span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a>)</span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a><span class="co"># Initialize estimators</span></span>
<span id="cb7-9"><a href="#cb7-9" tabindex="-1"></a>rf_reg <span class="op">=</span> RandomForestRegressor(random_state<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb7-10"><a href="#cb7-10" tabindex="-1"></a>gb_reg <span class="op">=</span> GradientBoostingRegressor(random_state<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb7-11"><a href="#cb7-11" tabindex="-1"></a>linear_reg <span class="op">=</span> LinearRegression()</span>
<span id="cb7-12"><a href="#cb7-12" tabindex="-1"></a>voting_reg <span class="op">=</span> VotingRegressor([(<span class="st">"rf"</span>, rf_reg), (<span class="st">"gb"</span>, gb_reg), (<span class="st">"lr"</span>, linear_reg)])</span>
<span id="cb7-13"><a href="#cb7-13" tabindex="-1"></a></span>
<span id="cb7-14"><a href="#cb7-14" tabindex="-1"></a><span class="co"># fit/train voting estimator</span></span>
<span id="cb7-15"><a href="#cb7-15" tabindex="-1"></a>voting_reg.fit(X_train, y_train)</span>
<span id="cb7-16"><a href="#cb7-16" tabindex="-1"></a></span>
<span id="cb7-17"><a href="#cb7-17" tabindex="-1"></a><span class="co"># lets also fit/train the individual models for comparison</span></span>
<span id="cb7-18"><a href="#cb7-18" tabindex="-1"></a>rf_reg.fit(X_train, y_train)</span>
<span id="cb7-19"><a href="#cb7-19" tabindex="-1"></a>gb_reg.fit(X_train, y_train)</span>
<span id="cb7-20"><a href="#cb7-20" tabindex="-1"></a>linear_reg.fit(X_train, y_train)</span></code></pre>
</div>
<p>We fit the voting regressor in the same way we would fit a single
model. When the voting regressor is instantiated we pass it a parameter
containing a list of tuples that contain the estimators we wish to
stack: in this case the random forest, gradient boosting and linear
regressors. To get a sense of what this is doing lets predict the first
20 samples in the test portion of the data and plot the results.</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a><span class="co"># make predictions</span></span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a>X_test_20 <span class="op">=</span> X_test[:<span class="dv">20</span>] <span class="co"># first 20 for visualisation</span></span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a></span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a>rf_pred <span class="op">=</span> rf_reg.predict(X_test_20)</span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a>gb_pred <span class="op">=</span> gb_reg.predict(X_test_20)</span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a>linear_pred <span class="op">=</span> linear_reg.predict(X_test_20)</span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a>voting_pred <span class="op">=</span> voting_reg.predict(X_test_20)</span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a></span>
<span id="cb8-11"><a href="#cb8-11" tabindex="-1"></a>plt.figure()</span>
<span id="cb8-12"><a href="#cb8-12" tabindex="-1"></a>plt.plot(gb_pred,  <span class="st">"o"</span>, color<span class="op">=</span><span class="st">"black"</span>, label<span class="op">=</span><span class="st">"GradientBoostingRegressor"</span>)</span>
<span id="cb8-13"><a href="#cb8-13" tabindex="-1"></a>plt.plot(rf_pred,  <span class="st">"o"</span>, color<span class="op">=</span><span class="st">"blue"</span>, label<span class="op">=</span><span class="st">"RandomForestRegressor"</span>)</span>
<span id="cb8-14"><a href="#cb8-14" tabindex="-1"></a>plt.plot(linear_pred,  <span class="st">"o"</span>, color<span class="op">=</span><span class="st">"green"</span>, label<span class="op">=</span><span class="st">"LinearRegression"</span>)</span>
<span id="cb8-15"><a href="#cb8-15" tabindex="-1"></a>plt.plot(voting_pred,  <span class="st">"x"</span>, color<span class="op">=</span><span class="st">"red"</span>, ms<span class="op">=</span><span class="dv">10</span>, label<span class="op">=</span><span class="st">"VotingRegressor"</span>)</span>
<span id="cb8-16"><a href="#cb8-16" tabindex="-1"></a></span>
<span id="cb8-17"><a href="#cb8-17" tabindex="-1"></a>plt.tick_params(axis<span class="op">=</span><span class="st">"x"</span>, which<span class="op">=</span><span class="st">"both"</span>, bottom<span class="op">=</span><span class="va">False</span>, top<span class="op">=</span><span class="va">False</span>, labelbottom<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb8-18"><a href="#cb8-18" tabindex="-1"></a>plt.ylabel(<span class="st">"predicted"</span>)</span>
<span id="cb8-19"><a href="#cb8-19" tabindex="-1"></a>plt.xlabel(<span class="st">"training samples"</span>)</span>
<span id="cb8-20"><a href="#cb8-20" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">"best"</span>)</span>
<span id="cb8-21"><a href="#cb8-21" tabindex="-1"></a>plt.title(<span class="st">"Regressor predictions and their average"</span>)</span>
<span id="cb8-22"><a href="#cb8-22" tabindex="-1"></a></span>
<span id="cb8-23"><a href="#cb8-23" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<figure><img src="../fig/house_price_voting_regressor.svg" alt="A plot showing the predictions of different regression models on the same dataset. Each model's predictions are represented by different colored markers, and the voting regressor's predictions are shown as larger red crosses." class="figure mx-auto d-block"><div class="figcaption">Regressor predictions and average from
stack</div>
</figure><p>Finally, lets see how the average compares against each single
estimator in the stack?</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'random forest: </span><span class="sc">{</span>rf_reg<span class="sc">.</span>score(X_test, y_test)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'gradient boost: </span><span class="sc">{</span>gb_reg<span class="sc">.</span>score(X_test, y_test)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a></span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'linear regression: </span><span class="sc">{</span>linear_reg<span class="sc">.</span>score(X_test, y_test)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'voting regressor: </span><span class="sc">{</span>voting_reg<span class="sc">.</span>score(X_test, y_test)<span class="sc">}</span><span class="ss">'</span>)</span></code></pre>
</div>
<p>Each of our models score between 0.61-0.82, which at the high end is
good, but at the low end is a pretty poor prediction accuracy score. Do
note that the toy datasets are not representative of real world data.
However what we can see is that the stacked result generated by the
voting regressor fits different sub-models and then averages the
individual predictions to form a final prediction. The benefit of this
approach is that, it reduces overfitting and increases generalizability.
Of course, we could try and improve our accuracy score by tweaking with
our indivdual model hyperparameters, using more advaced boosted models
or adjusting our training data features and train-test-split data.</p>
<div id="exercise-stacking-a-classification-problem." class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="exercise-stacking-a-classification-problem." class="callout-inner">
<h3 class="callout-title">Exercise: Stacking a classification problem.</h3>
<div class="callout-content">
<p>Scikit learn also has method for stacking ensemble classifiers
<code>sklearn.ensemble.VotingClassifier</code> do you think you could
apply a stack to the penguins dataset using a random forest, SVM and
decision tree classifier, or a selection of any other classifier
estimators available in sci-kit learn?</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a>penguins <span class="op">=</span> sns.load_dataset(<span class="st">'penguins'</span>)</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a>feature_names <span class="op">=</span> [<span class="st">'bill_length_mm'</span>, <span class="st">'bill_depth_mm'</span>, <span class="st">'flipper_length_mm'</span>, <span class="st">'body_mass_g'</span>]</span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a>penguins.dropna(subset<span class="op">=</span>feature_names, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a>species_names <span class="op">=</span> penguins[<span class="st">'species'</span>].unique()</span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a><span class="co"># Define data and targets</span></span>
<span id="cb10-9"><a href="#cb10-9" tabindex="-1"></a>X <span class="op">=</span> penguins[feature_names]</span>
<span id="cb10-10"><a href="#cb10-10" tabindex="-1"></a></span>
<span id="cb10-11"><a href="#cb10-11" tabindex="-1"></a>y <span class="op">=</span> penguins.species</span>
<span id="cb10-12"><a href="#cb10-12" tabindex="-1"></a></span>
<span id="cb10-13"><a href="#cb10-13" tabindex="-1"></a><span class="co"># Split data in training and test set</span></span>
<span id="cb10-14"><a href="#cb10-14" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb10-15"><a href="#cb10-15" tabindex="-1"></a></span>
<span id="cb10-16"><a href="#cb10-16" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb10-17"><a href="#cb10-17" tabindex="-1"></a></span>
<span id="cb10-18"><a href="#cb10-18" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'train size: </span><span class="sc">{</span>X_train<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb10-19"><a href="#cb10-19" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'test size: </span><span class="sc">{</span>X_test<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">'</span>)</span></code></pre>
</div>
<p>The code above loads the penguins data and splits it into test and
training portions. Have a play around with stacking some classifiers
using the <code>sklearn.ensemble.VotingClassifier</code> using the code
comments below as a guide.</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="co"># import classifiers</span></span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a><span class="co"># instantiate classifiers</span></span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a><span class="co"># fit classifiers</span></span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" tabindex="-1"></a><span class="co"># instantiate voting classifier and fit data</span></span>
<span id="cb11-8"><a href="#cb11-8" tabindex="-1"></a></span>
<span id="cb11-9"><a href="#cb11-9" tabindex="-1"></a><span class="co"># make predictions</span></span>
<span id="cb11-10"><a href="#cb11-10" tabindex="-1"></a></span>
<span id="cb11-11"><a href="#cb11-11" tabindex="-1"></a><span class="co"># compare scores</span></span></code></pre>
</div>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">

</div>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points</h3>
<div class="callout-content">
<ul><li>Ensemble methods can be used to reduce under/over fitting training
data.</li>
</ul></div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</div>
</section></div> <!-- / div.lesson-content -->
    </main><!-- / main#main-content.main-content --><nav class="bottom-pagination mx-md-4" aria-label="Previous and Next Chapter"><div class="d-block d-sm-block d-md-none">
        <a class="chapter-link" href="../instructor/03-classification.html"><i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>Previous</a>
        <a class="chapter-link float-end" href="../instructor/05-clustering.html">Next<i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i></a>
      </div>
      <!-- content for large screens -->
      <div class="d-none d-sm-none d-md-block">
        <a class="chapter-link" href="../instructor/03-classification.html" rel="prev">
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>
          Previous: Supervised methods -
        </a>
        <a class="chapter-link float-end" href="../instructor/05-clustering.html" rel="next">
          Next: Unsupervised methods...
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i>
        </a>
      </div>
    </nav></div> <!-- / div.primary-content.col-xs-12 -->
<!-- END:   inst/pkgdown/templates/content-instructor.html-->

      </div><!--/div.row-->
      		<footer class="row footer mx-md-3"><hr><div class="col-md-6">
        <p>This lesson is subject to the <a href="CODE_OF_CONDUCT.html">Code of Conduct</a></p>
        <p>

        <a href="https://github.com/jonathan-hartman/machine-learning-novice-sklearn/edit/main/episodes/04-ensemble-methods.md" class="external-link">Edit on GitHub</a>

	
        | <a href="https://github.com/jonathan-hartman/machine-learning-novice-sklearn/blob/main/CONTRIBUTING.md" class="external-link">Contributing</a>
        | <a href="https://github.com/jonathan-hartman/machine-learning-novice-sklearn/" class="external-link">Source</a></p>
				<p><a href="https://github.com/jonathan-hartman/machine-learning-novice-sklearn/blob/main/CITATION.cff" class="external-link">Cite</a> | <a href="mailto:hartman@itc.rwth-aachen.de">Contact</a> | <a href="https://carpentries.org/about/" class="external-link">About</a></p>
			</div>
			<div class="col-md-6">

        <p>Materials licensed under <a href="LICENSE.html">CC-BY 4.0</a> by the authors</p>

        <p>Template licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/" class="external-link">CC-BY 4.0</a> by <a href="https://carpentries.org/" class="external-link">The Carpentries</a></p>
        <p>Built with <a href="https://github.com/carpentries/sandpaper/tree/0.16.12" class="external-link">sandpaper (0.16.12)</a>, <a href="https://github.com/carpentries/pegboard/tree/0.7.9" class="external-link">pegboard (0.7.9)</a>, and <a href="https://github.com/carpentries/varnish/tree/1.0.6" class="external-link">varnish (1.0.6)</a></p>
			</div>
		</footer></div> <!-- / div.container -->
	<div id="to-top">
		<a href="#top">
      <i class="search-icon" data-feather="arrow-up" role="img" aria-label="Back To Top"></i><br><!-- <span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top --><span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top
		</a>
	</div>
  <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "LearningResource",
  "@id": "https://jonathan-hartman.github.io/machine-learning-novice-sklearn/instructor/04-ensemble-methods.html",
  "inLanguage": "en",
  "dct:conformsTo": "https://bioschemas.org/profiles/LearningResource/1.0-RELEASE",
  "description": "A Carpentries Lesson teaching foundational data and coding skills to researchers worldwide",
  "keywords": "machine learning, python, sklearn, The Carpentries",
  "name": "Ensemble methods",
  "creativeWorkStatus": "active",
  "url": "https://jonathan-hartman.github.io/machine-learning-novice-sklearn/instructor/04-ensemble-methods.html",
  "identifier": "https://jonathan-hartman.github.io/machine-learning-novice-sklearn/instructor/04-ensemble-methods.html",
  "dateCreated": "2025-07-23",
  "dateModified": "2025-07-23",
  "datePublished": "2025-07-23"
}

  </script><script>
		feather.replace();
	</script></body></html><!-- END:   inst/pkgdown/templates/layout.html-->

