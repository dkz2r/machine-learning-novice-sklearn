<!DOCTYPE html>
<!-- START: inst/pkgdown/templates/layout.html --><!-- Generated by pkgdown: do not edit by hand --><html lang="en" data-bs-theme="auto"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><title>Introduction to Machine Learning with Scikit Learn: Supervised methods - Classification</title><meta name="viewport" content="width=device-width, initial-scale=1"><script src="../assets/themetoggle.js"></script><link rel="stylesheet" type="text/css" href="../assets/styles.css"><script src="../assets/scripts.js" type="text/javascript"></script><!-- mathjax --><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      config: ["MMLorHTML.js"],
      jax: ["input/TeX","input/MathML","output/HTML-CSS","output/NativeMML", "output/PreviewHTML"],
      extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
      TeX: {
        extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
      },
      tex2jax: {
        inlineMath: [['\\(', '\\)']],
        displayMath: [ ['$$','$$'], ['\\[', '\\]'] ],
        processEscapes: true
      }
    });
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><!-- Responsive Favicon for The Carpentries --><link rel="apple-touch-icon" sizes="180x180" href="../favicons/incubator/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="../favicons/incubator/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="../favicons/incubator/favicon-16x16.png"><link rel="manifest" href="../favicons/incubator/site.webmanifest"><link rel="mask-icon" href="../favicons/incubator/safari-pinned-tab.svg" color="#5bbad5"><meta name="msapplication-TileColor" content="#da532c"><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"><meta name="theme-color" media="(prefers-color-scheme: dark)" content="black"></head><body>
    <header id="top" class="navbar navbar-expand-md top-nav incubator"><svg xmlns="http://www.w3.org/2000/svg" class="d-none"><symbol id="check2" viewbox="0 0 16 16"><path d="M13.854 3.646a.5.5 0 0 1 0 .708l-7 7a.5.5 0 0 1-.708 0l-3.5-3.5a.5.5 0 1 1 .708-.708L6.5 10.293l6.646-6.647a.5.5 0 0 1 .708 0z"></path></symbol><symbol id="circle-half" viewbox="0 0 16 16"><path d="M8 15A7 7 0 1 0 8 1v14zm0 1A8 8 0 1 1 8 0a8 8 0 0 1 0 16z"></path></symbol><symbol id="moon-stars-fill" viewbox="0 0 16 16"><path d="M6 .278a.768.768 0 0 1 .08.858 7.208 7.208 0 0 0-.878 3.46c0 4.021 3.278 7.277 7.318 7.277.527 0 1.04-.055 1.533-.16a.787.787 0 0 1 .81.316.733.733 0 0 1-.031.893A8.349 8.349 0 0 1 8.344 16C3.734 16 0 12.286 0 7.71 0 4.266 2.114 1.312 5.124.06A.752.752 0 0 1 6 .278z"></path><path d="M10.794 3.148a.217.217 0 0 1 .412 0l.387 1.162c.173.518.579.924 1.097 1.097l1.162.387a.217.217 0 0 1 0 .412l-1.162.387a1.734 1.734 0 0 0-1.097 1.097l-.387 1.162a.217.217 0 0 1-.412 0l-.387-1.162A1.734 1.734 0 0 0 9.31 6.593l-1.162-.387a.217.217 0 0 1 0-.412l1.162-.387a1.734 1.734 0 0 0 1.097-1.097l.387-1.162zM13.863.099a.145.145 0 0 1 .274 0l.258.774c.115.346.386.617.732.732l.774.258a.145.145 0 0 1 0 .274l-.774.258a1.156 1.156 0 0 0-.732.732l-.258.774a.145.145 0 0 1-.274 0l-.258-.774a1.156 1.156 0 0 0-.732-.732l-.774-.258a.145.145 0 0 1 0-.274l.774-.258c.346-.115.617-.386.732-.732L13.863.1z"></path></symbol><symbol id="sun-fill" viewbox="0 0 16 16"><path d="M8 12a4 4 0 1 0 0-8 4 4 0 0 0 0 8zM8 0a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 0zm0 13a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 13zm8-5a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2a.5.5 0 0 1 .5.5zM3 8a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2A.5.5 0 0 1 3 8zm10.657-5.657a.5.5 0 0 1 0 .707l-1.414 1.415a.5.5 0 1 1-.707-.708l1.414-1.414a.5.5 0 0 1 .707 0zm-9.193 9.193a.5.5 0 0 1 0 .707L3.05 13.657a.5.5 0 0 1-.707-.707l1.414-1.414a.5.5 0 0 1 .707 0zm9.193 2.121a.5.5 0 0 1-.707 0l-1.414-1.414a.5.5 0 0 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .707zM4.464 4.465a.5.5 0 0 1-.707 0L2.343 3.05a.5.5 0 1 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .708z"></path></symbol></svg><a class="visually-hidden-focusable skip-link" href="#main-content">Skip to main content</a>
  <div class="container-fluid top-nav-container">
    <div class="col-md-8">
      <div class="large-logo">
        <img id="incubator-logo" alt="Carpentries Incubator" src="../assets/images/incubator-logo.svg"><span class="badge text-bg-warning">
          <abbr title="This lesson is in the alpha phase, which means that it has been taught once and lesson authors are iterating on feedback.">
            <a href="https://docs.carpentries.org/resources/curriculum/lesson-life-cycle.html" class="external-link alert-link">
              <i aria-hidden="true" class="icon" data-feather="alert-triangle" style="border-radius: 5px"></i>
              Alpha
            </a>
            <span class="visually-hidden">This lesson is in the alpha phase, which means that it has been taught once and lesson authors are iterating on feedback.</span>
          </abbr>
        </span>

      </div>
    </div>
    <div class="selector-container">
      <div id="theme-selector">
        <li class="nav-item dropdown" id="theme-button-list">
          <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
            <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="bd-theme-text"><li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                Light
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                Dark
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                Auto
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
          </ul></li>
      </div>

      <div class="dropdown" id="instructor-dropdown">
        <button class="btn btn-secondary dropdown-toggle bordered-button" type="button" id="dropdownMenu1" data-bs-toggle="dropdown" aria-expanded="false">
          <i aria-hidden="true" class="icon" data-feather="eye"></i> Instructor View <i data-feather="chevron-down"></i>
        </button>
        <ul class="dropdown-menu" aria-labelledby="dropdownMenu1"><li><button class="dropdown-item" type="button" onclick="window.location.href='../03-classification.html';">Learner View</button></li>
        </ul></div>
    </div>
  </div>
  <hr></header><nav class="navbar navbar-expand-xl bottom-nav incubator" aria-label="Main Navigation"><div class="container-fluid nav-container">
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle Navigation">
      <span class="navbar-toggler-icon"></span>
      <span class="menu-title">Menu</span>
    </button>
    <div class="nav-logo">
      <img class="small-logo" alt="Carpentries Incubator" src="../assets/images/incubator-logo-sm.svg"></div>
    <div class="lesson-title-md">
      Introduction to Machine Learning with Scikit Learn
    </div>
    <div class="search-icon-sm">
      <!-- TODO: do not show until we have search
        <i role="img" aria-label="Search the All In One page" data-feather="search"></i>
      -->
    </div>
    <div class="desktop-nav">
      <ul class="navbar-nav me-auto mb-2 mb-lg-0"><li class="nav-item">
          <span class="lesson-title">
            Introduction to Machine Learning with Scikit Learn
          </span>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/key-points.html">Key Points</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/instructor-notes.html">Instructor Notes</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/images.html">Extract All Images</a>
        </li>
        <li class="nav-item dropdown">
          <button class="nav-link dropdown-toggle" id="navbarDropdown" data-bs-toggle="dropdown" aria-expanded="false">
            More <i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu" aria-labelledby="navbarDropdown"><li><a class="dropdown-item" href="guide.html">Instructor Notes</a></li><hr><li><a class="dropdown-item" href="reference.html">Reference</a></li>
          </ul></li>
      </ul></div>
    <!--
    <form class="d-flex col-md-2 search-form">
      <fieldset disabled>
      <input class="form-control me-2 searchbox" type="search" placeholder="" aria-label="">
        <button class="btn btn-outline-success tablet-search-button"  type="submit">
          <i class="search-icon" data-feather="search" role="img" aria-label="Search the All In One page"></i>
        </button>
      </fieldset>
    </form>
    -->
    <a id="search-button" class="btn btn-primary" href="../instructor/aio.html" role="button" aria-label="Search the All In One page">Search the All In One page</a>
  </div><!--/div.container-fluid -->
</nav><div class="col-md-12 mobile-title">
  Introduction to Machine Learning with Scikit Learn
</div>

<aside class="col-md-12 lesson-progress"><div style="width: 30%" class="percentage">
    30%
  </div>
  <div class="progress incubator">
    <div class="progress-bar incubator" role="progressbar" style="width: 30%" aria-valuenow="30" aria-label="Lesson Progress" aria-valuemin="0" aria-valuemax="100">
    </div>
  </div>
</aside><div class="container">
      <div class="row">
        <!-- START: inst/pkgdown/templates/navbar.html -->
<div id="sidebar-col" class="col-lg-4">
  <div id="sidebar" class="sidebar">
      <nav aria-labelledby="flush-headingEleven"><button role="button" aria-label="close menu" alt="close menu" aria-expanded="true" aria-controls="sidebar" class="collapse-toggle" data-collapse="Collapse " data-episodes="Episodes ">
          <i class="search-icon" data-feather="x" role="img"></i>
        </button>
        <div class="sidebar-inner">
          <div class="row mobile-row" id="theme-row-mobile">
            <div class="col" id="theme-selector">
              <li class="nav-item dropdown" id="theme-button-list">
                <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
                  <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><span class="d-lg-none ms-1" id="bd-theme-text">Toggle Theme</span>
                </button>
                <ul class="dropdown-menu dropdown-menu-right" aria-labelledby="bd-theme-text"><li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                      Light
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                      Dark
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                      <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                      Auto
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                </ul></li>
            </div>
          </div>
          <div class="row mobile-row">
            <div class="col">
              <div class="sidenav-view-selector">
                <div class="accordion accordion-flush" id="accordionFlush9">
                  <div class="accordion-item">
                    <h2 class="accordion-header" id="flush-headingNine">
                      <button class="accordion-button collapsed" id="instructor" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseNine" aria-expanded="false" aria-controls="flush-collapseNine">
                        <i id="eye" aria-hidden="true" class="icon" data-feather="eye"></i> Instructor View
                      </button>
                    </h2>
                    <div id="flush-collapseNine" class="accordion-collapse collapse" aria-labelledby="flush-headingNine" data-bs-parent="#accordionFlush2">
                      <div class="accordion-body">
                        <a href="../03-classification.html">Learner View</a>
                      </div>
                    </div>
                  </div><!--/div.accordion-item-->
                </div><!--/div.accordion-flush-->
              </div><!--div.sidenav-view-selector -->
            </div><!--/div.col -->

            <hr></div><!--/div.mobile-row -->

          <div class="accordion accordion-flush" id="accordionFlush11">
            <div class="accordion-item">

              <button id="chapters" class="accordion-button show" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseEleven" aria-expanded="false" aria-controls="flush-collapseEleven">
                <h2 class="accordion-header chapters" id="flush-headingEleven">
                  EPISODES
                </h2>
              </button>
              <div id="flush-collapseEleven" class="accordion-collapse show collapse" aria-labelledby="flush-headingEleven" data-bs-parent="#accordionFlush11">

                <div class="accordion-body">
                  <div class="accordion accordion-flush" id="accordionFlush1">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading1">
        <a href="index.html">Summary and Schedule</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush2">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading2">
        <a href="01-introduction.html">1. Introduction</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush3">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading3">
        <a href="02-regression.html">2. Supervised methods - Regression</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlushcurrent">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-headingcurrent">
      <button class="accordion-button" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapsecurrent" aria-expanded="true" aria-controls="flush-collapsecurrent">
        <span class="visually-hidden">Current Chapter</span>
        <span class="current-chapter">
        3. Supervised methods - Classification
        </span>
      </button>
    </div><!--/div.accordion-header-->

    <div id="flush-collapsecurrent" class="accordion-collapse collapse show" aria-labelledby="flush-headingcurrent" data-bs-parent="#accordionFlushcurrent">
      <div class="accordion-body">
        <ul><li><a href="#classification">Classification</a></li>
<li><a href="#the-penguins-dataset">The penguins dataset</a></li>
<li><a href="#training-testing-split">Training-testing split</a></li>
<li><a href="#classification-using-a-decision-tree">Classification using a decision tree</a></li>
<li><a href="#inspecting-an-over-fitted-decision-tree">Inspecting an over-fitted decision tree</a></li>
<li><a href="#classification-using-support-vector-machines">Classification using support vector machines</a></li>
        </ul></div><!--/div.accordion-body-->
    </div><!--/div.accordion-collapse-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush5">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading5">
        <a href="04-ensemble-methods.html">4. Ensemble methods</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush6">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading6">
        <a href="05-clustering.html">5. Unsupervised methods - Clustering</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush7">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading7">
        <a href="06-dimensionality-reduction.html">6. Unsupervised methods - Dimensionality reduction</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush8">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading8">
        <a href="07-neural-networks.html">7. Neural Networks</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush9">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading9">
        <a href="08-ethics.html">8. Ethics and the Implications of Machine Learning</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush10">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading10">
        <a href="09-learn-more.html">9. Find out more</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

                </div>
              </div>
            </div>

            <hr class="half-width"><div class="accordion accordion-flush lesson-resources" id="accordionFlush12">
              <div class="accordion-item">
                <h2 class="accordion-header" id="flush-headingTwelve">
                  <button class="accordion-button collapsed" id="lesson-resources" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseTwelve" aria-expanded="false" aria-controls="flush-collapseTwelve">
                    RESOURCES
                  </button>
                </h2>
                <div id="flush-collapseTwelve" class="accordion-collapse collapse" aria-labelledby="flush-headingTwelve" data-bs-parent="#accordionFlush12">
                  <div class="accordion-body">
                    <ul><li>
                        <a href="../instructor/key-points.html">Key Points</a>
                      </li>
                      <li>
                        <a href="../instructor/instructor-notes.html">Instructor Notes</a>
                      </li>
                      <li>
                        <a href="../instructor/images.html">Extract All Images</a>
                      </li>
                      <li><a href="guide.html">Instructor Notes</a></li><hr><li><a class="dropdown-item" href="reference.html">Reference</a></li>
                    </ul></div>
                </div>
              </div>
            </div>
            <hr class="half-width lesson-resources"><a href="../instructor/aio.html">See all in one page</a>


            <hr class="d-none d-sm-block d-md-none"><div class="d-grid gap-1">

            </div>
          </div><!-- /div.accordion -->
        </div><!-- /div.sidebar-inner -->
      </nav></div><!-- /div.sidebar -->
  </div><!-- /div.sidebar-col -->
<!-- END:   inst/pkgdown/templates/navbar.html-->

        <!-- START: inst/pkgdown/templates/content-instructor.html -->
  <div class="col-xl-8 col-lg-12 primary-content">
    <nav class="lesson-content mx-md-4" aria-label="Previous and Next Chapter"><!-- content for small screens --><div class="d-block d-sm-block d-md-none">
        <a class="chapter-link" href="../instructor/02-regression.html"><i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>Previous</a>
        <a class="chapter-link float-end" href="../instructor/04-ensemble-methods.html">Next<i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i></a>
      </div>
      <!-- content for large screens -->
      <div class="d-none d-sm-none d-md-block">
        <a class="chapter-link" href="../instructor/02-regression.html" rel="prev">
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>
          Previous: Supervised methods -
        </a>
        <a class="chapter-link float-end" href="../instructor/04-ensemble-methods.html" rel="next">
          Next: Ensemble methods...
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i>
        </a>
      </div>
      <hr></nav><main id="main-content" class="main-content"><div class="container lesson-content">
        <h1>Supervised methods - Classification</h1>
        <p>Last updated on 2025-07-23 |

        <a href="https://github.com/jonathan-hartman/machine-learning-novice-sklearn/edit/main/episodes/03-classification.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>



        <p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 60 minutes</p>

        <div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>

        

<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul><li>How can I classify data into known categories?</li>
</ul></div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul><li>Use two different supervised methods to classify data.</li>
<li>Learn about the concept of hyper-parameters.</li>
<li>Learn to validate and cross-validate models</li>
</ul></div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="classification">Classification<a class="anchor" aria-label="anchor" href="#classification"></a></h2>
<hr class="half-width"><p>Classification is a supervised method to recognise and group data
objects into a pre-determined categories. Where regression uses labelled
observations to predict a continuous numerical value, classification
predicts a discrete categorical fit to a class. Classification in ML
leverages a wide range of algorithms to classify a set of data/datasets
into their respective categories.</p>
<p>In this episode we are going to introduce the concept of supervised
classification by classifying penguin data into different species of
penguins using Scikit-Learn.</p>
</section><section><h2 class="section-heading" id="the-penguins-dataset">The penguins dataset<a class="anchor" aria-label="anchor" href="#the-penguins-dataset"></a></h2>
<hr class="half-width"><p>We’re going to be using the <a href="https://github.com/allisonhorst/palmerpenguins" class="external-link">Palmer Penguins
dataset</a> of Allison Horst, The dataset contains 344 size measurements
for three penguin species (Chinstrap, Gentoo and Adélie) observed on
three islands in the Palmer Archipelago, Antarctica.</p>
<figure><img src="../fig/palmer_penguins.png" alt="A cartoon image of three penguins standing on a snowy island. The penguins are labelled as Chinstrap, Gentoo and Adélie." class="figure mx-auto d-block"><div class="figcaption"><em>Artwork by <span class="citation">@allison_horst</span></em></div>
</figure><p>The physical attributes measured are flipper length, beak length,
beak width, body mass, and sex. <img src="../fig/culmen_depth.png" alt="A drawn image of a penguin's head, showing where bill length and bill depth are measured." class="figure"></p>
<p>In other words, the dataset contains 344 rows with 7 features i.e. 5
physical attributes, species and the island where the observations were
made.</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a>dataset <span class="op">=</span> sns.load_dataset(<span class="st">'penguins'</span>)</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a>dataset.head()</span></code></pre>
</div>
<p>Our aim is to develop a classification model that will predict the
species of a penguin based upon measurements of those variables.</p>
<p>As a rule of thumb for ML/DL modelling, it is best to start with a
simple model and progressively add complexity in order to meet our
desired classification performance.</p>
<p>For this lesson we will limit our dataset to only numerical values
such as bill_length, bill_depth, flipper_length, and body_mass while we
attempt to classify species.</p>
<p>The above table contains multiple categorical objects such as
species. If we attempt to include the other categorical fields, island
and sex, we might hinder classification performance due to the
complexity of the data.</p>
<div class="section level3">
<h3 id="preprocessing-our-data">Preprocessing our data<a class="anchor" aria-label="anchor" href="#preprocessing-our-data"></a></h3>
<p>Lets do some pre-processing on our dataset and specify our
<code>X</code> features and <code>y</code> labels:</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="co"># Extract the data we need</span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>feature_names <span class="op">=</span> [<span class="st">'bill_length_mm'</span>, <span class="st">'bill_depth_mm'</span>, <span class="st">'flipper_length_mm'</span>, <span class="st">'body_mass_g'</span>]</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>dataset.dropna(subset<span class="op">=</span>feature_names, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>class_names <span class="op">=</span> dataset[<span class="st">'species'</span>].unique()</span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a>X <span class="op">=</span> dataset[feature_names]</span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a>y <span class="op">=</span> dataset[<span class="st">'species'</span>]</span></code></pre>
</div>
<p>Having extracted our features <code>X</code> and labels
<code>y</code>, we can now split the data using the
<code>train_test_split</code> function.</p>
</div>
</section><section><h2 class="section-heading" id="training-testing-split">Training-testing split<a class="anchor" aria-label="anchor" href="#training-testing-split"></a></h2>
<hr class="half-width"><p>When undertaking any machine learning project, it’s important to be
able to evaluate how well your model works.</p>
<p>Rather than evaluating this manually we can instead set aside some of
our training data, usually 20% of our training data, and use these as a
testing dataset. We then train on the remaining 80% and use the testing
dataset to evaluate the accuracy of our trained model.</p>
<p>We lose a bit of training data in the process, But we can now easily
evaluate the performance of our model. With more advanced test-train
split techniques we can even recover this lost training data!</p>
<div id="why-do-we-do-this" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="why-do-we-do-this" class="callout-inner">
<h3 class="callout-title">Why do we do this?</h3>
<div class="callout-content">
<p>It’s important to do this early, and to do all of your work with the
training dataset - this avoids any risk of you introducing bias to the
model based on your own manual observations of data in the testing set
(afterall, we want the model to make the decisions about parameters!).
This can also highlight when you are over-fitting on your training
data.</p>
</div>
</div>
</div>
<p>How we split the data into training and testing sets is also
extremely important. We need to make sure that our training data is
representitive of both our test data and actual data.</p>
<p>For classification problems this means we should ensure that each
class of interest is represented proportionately in both training and
testing sets. For regression problems we should ensure that our training
and test sets cover the range of feature values that we wish to
predict.</p>
<p>In the previous regression episode we created the penguin training
data by taking the first 146 samples our the dataset. Unfortunately the
penguin data is sorted by species and so our training data only
considered one type of penguin and thus was not representitive of the
actual data we tried to fit. We could have avoided this issue by
randomly shuffling our penguin samples before splitting the data.</p>
<div id="when-not-to-shuffle-your-data" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="when-not-to-shuffle-your-data" class="callout-inner">
<h3 class="callout-title">When not to shuffle your data</h3>
<div class="callout-content">
<p>Sometimes your data is dependant on it’s ordering, such as
time-series data where past values influence future predictions.
Creating train-test splits for this can be tricky at first glance, but
fortunately there are existing techniques to tackle this (often called
stratification): See <a href="https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-iterators" class="external-link">Scikit-Learn</a>
for more information.</p>
</div>
</div>
</div>
<p>We specify the fraction of data to use as test data, and the function
randomly shuffles our data prior to splitting:</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">0</span>)</span></code></pre>
</div>
<p>We’ll use <code>X_train</code> and <code>y_train</code> to develop
our model, and only look at <code>X_test</code> and <code>y_test</code>
when it’s time to evaluate its performance.</p>
<div class="section level3">
<h3 id="visualising-the-data">Visualising the data<a class="anchor" aria-label="anchor" href="#visualising-the-data"></a></h3>
<p>In order to better understand how a model might classify this data,
we can first take a look at the data visually, to see what patterns we
might identify.</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>fig01 <span class="op">=</span> sns.scatterplot(X_train, x<span class="op">=</span>feature_names[<span class="dv">0</span>], y<span class="op">=</span>feature_names[<span class="dv">1</span>], hue<span class="op">=</span>dataset[<span class="st">'species'</span>])</span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<figure><img src="../fig/e3_penguins_vis.png" alt="A scatter plot of the penguin dataset, showing bill length on the x-axis and bill depth on the y-axis. The points are coloured by species. There are three clusters of points, one for each species, with some overlap between the species." class="figure mx-auto d-block"><div class="figcaption">Visualising the penguins dataset</div>
</figure><p>As there are four measurements for each penguin, we need quite a few
plots to visualise all four dimensions against each other. Here is a
handy Seaborn function to do so:</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a>sns.pairplot(dataset, hue<span class="op">=</span><span class="st">"species"</span>)</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<figure><img src="../fig/pairplot.png" alt="A pairplot of the penguin dataset, showing scatter plots of each pair of features. The points are coloured by species. There are three clusters of points, one for each species, with some overlap between the species." class="figure mx-auto d-block"><div class="figcaption">Visualising the penguins dataset</div>
</figure><p>We can see that penguins from each species form fairly distinct
spatial clusters in these plots, so that you could draw lines between
those clusters to delineate each species. This is effectively what many
classification algorithms do. They use the training data to delineate
the observation space, in this case the 4 measurement dimensions, into
classes. When given a new observation, the model finds which of those
class areas the new observation falls in to.</p>
</div>
</section><section><h2 class="section-heading" id="classification-using-a-decision-tree">Classification using a decision tree<a class="anchor" aria-label="anchor" href="#classification-using-a-decision-tree"></a></h2>
<hr class="half-width"><p>We’ll first apply a decision tree classifier to the data. Decisions
trees are conceptually similar to flow diagrams (or more precisely for
the biologists: dichotomous keys). They split the classification problem
into a binary tree of comparisons, at each step comparing a measurement
to a value, and moving left or right down the tree until a
classification is reached.</p>
<figure><img src="../fig/decision_tree_example.png" alt="A decision tree example showing how one might classify four species of animals based on their features. The tree starts with 'Has feathers?' and branches into 'Can Fly?' and 'Has fur?'. The outcomes are Hawk, Penguin, Bear, and Dolphin" class="figure mx-auto d-block"><div class="figcaption">Decision tree for classifying penguins</div>
</figure><p>Training and using a decision tree in Scikit-Learn is
straightforward:</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier, plot_tree</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a>clf <span class="op">=</span> DecisionTreeClassifier(max_depth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a>clf.fit(X_train, y_train)</span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a>clf.predict(X_test)</span></code></pre>
</div>
<div id="hyper-parameters-parameters-that-tune-a-model" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="hyper-parameters-parameters-that-tune-a-model" class="callout-inner">
<h3 class="callout-title">Hyper-parameters: parameters that tune a model</h3>
<div class="callout-content">
<p>‘Max Depth’ is an example of a <em>hyper-parameter</em> for the
decision tree model. Where models use the parameters of an observation
to predict a result, hyper-parameters are used to tune how a model
works. Each model you encounter will have its own set of
hyper-parameters, each of which affects model behaviour and performance
in a different way. The process of adjusting hyper-parameters in order
to improve model performance is called hyper-parameter tuning.</p>
</div>
</div>
</div>
<p>We can conveniently check how our model did with the .score()
function, which will make predictions and report what proportion of them
were accurate:</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a>clf_score <span class="op">=</span> clf.score(X_test, y_test)</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a><span class="bu">print</span>(clf_score)</span></code></pre>
</div>
<p>Our model reports an accuracy of ~98% on the test data! We can also
look at the decision tree that was generated:</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a>fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">10</span>))</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a>plot_tree(clf, class_names<span class="op">=</span>class_names, feature_names<span class="op">=</span>feature_names, filled<span class="op">=</span><span class="va">True</span>, ax<span class="op">=</span>fig.gca())</span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<figure><img src="../fig/e3_dt_2.png" alt="An auomatically generated decision tree based on the model we just trained, showing how the model makes decisions based on the penguin features. The tree has 2 levels, with the first level splitting on flipper length, the second level splitting on bill length and bill depth." class="figure mx-auto d-block"><div class="figcaption">Decision tree for classifying penguins</div>
</figure><p>The first first question (<code>depth=1</code>) splits the training
data into “Adelie” and “Gentoo” categories using the criteria
<code>flipper_length_mm &lt;= 206.5</code>, and the next two questions
(<code>depth=2</code>) split the “Adelie” and “Gentoo” categories into
“Adelie &amp; Chinstrap” and “Gentoo &amp; Chinstrap” predictions.</p>
<!-- We can see from this that there's some very tortuous logic being used to tease out every single observation in the training set. For example, the single purple Gentoo node at the bottom of the tree. If we truncated that branch to the second level (Chinstrap), we'd have a little inaccuracy, a total of 9 non-Chinstraps in with 48 Chinstraps, but a less convoluted model.

The tortuous logic, such as the bottom purple Gentoo node, is a clear indication that this model has been over-fitted. It has developed a very complex delineation of the classification space in order to match every single observation, which will likely lead to poor results for new observations.

We can see that rather than clean lines between species, the decision tree produces orthogonal regions as each decision only considers a single parameter. Again, we can see that the model is over-fitting as the decision space is far more complex than needed, with regions that only select a single point. -->
<div class="section level3">
<h3 id="visualising-the-classification-space">Visualising the classification space<a class="anchor" aria-label="anchor" href="#visualising-the-classification-space"></a></h3>
<p>We can visualise the classification space (decision tree boundaries)
to get a more intuitive feel for what it is doing.Note that our 2D plot
can only show two parameters at a time, so we will quickly visualise by
training a new model on only 2 features:</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="im">from</span> sklearn.inspection <span class="im">import</span> DecisionBoundaryDisplay</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a>f1 <span class="op">=</span> feature_names[<span class="dv">0</span>]</span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a>f2 <span class="op">=</span> feature_names[<span class="dv">3</span>]</span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a>clf <span class="op">=</span> DecisionTreeClassifier(max_depth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb9-7"><a href="#cb9-7" tabindex="-1"></a>clf.fit(X_train[[f1, f2]], y_train)</span>
<span id="cb9-8"><a href="#cb9-8" tabindex="-1"></a></span>
<span id="cb9-9"><a href="#cb9-9" tabindex="-1"></a>d <span class="op">=</span> DecisionBoundaryDisplay.from_estimator(clf, X_train[[f1, f2]])</span>
<span id="cb9-10"><a href="#cb9-10" tabindex="-1"></a></span>
<span id="cb9-11"><a href="#cb9-11" tabindex="-1"></a>sns.scatterplot(X_train, x<span class="op">=</span>f1, y<span class="op">=</span>f2, hue<span class="op">=</span>y_train, palette<span class="op">=</span><span class="st">"husl"</span>)</span>
<span id="cb9-12"><a href="#cb9-12" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<figure><img src="../fig/e3_dt_space_2.png" alt="A scatter plot of the penguin daaset, showing bill length on the x-axis and body mass on the y-axis. The points are coloured by species. The decision tree is shown as colored regions, with the boundaries between the regions being orthogonal lines. The regions are generally aligned with the species clusters, but there are several misclassifications." class="figure mx-auto d-block"><div class="figcaption">Classification space for our decision tree</div>
</figure><div id="tuning-the-max_depth-hyperparameter" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="tuning-the-max_depth-hyperparameter" class="callout-inner">
<h3 class="callout-title">Tuning the <code>max_depth</code>
hyperparameter</h3>
<div class="callout-content">
<p>Our decision tree using a <code>max_depth=2</code> is fairly simple
and there are still some incorrect predictions in our final
classifications. What happens if we increase the <code>max_depth</code>
hyperparameter? Will our model improve?</p>
<p>Write a loop to train a decision tree classifier with
<code>max_depth</code> values of 1, 2, 3, 4 and 5, and record the
accuracy of each model on the test data. Then plot the accuracy against
the <code>max_depth</code> values.</p>
<p>Yout might find the following code snippets useful:</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a>clf <span class="op">=</span> DecisionTreeClassifier(max_depth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a>clf.fit(X_train, y_train)</span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a>acc <span class="op">=</span> clf.score(X_test, y_test)</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a>sns.lineplot(acc_df, x<span class="op">=</span><span class="st">'depth'</span>, y<span class="op">=</span><span class="st">'accuracy'</span>)</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a>plt.xlabel(<span class="st">'Tree depth'</span>)</span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a>plt.ylabel(<span class="st">'Accuracy'</span>)</span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<p>What happens? Why?</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a>max_depths <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>]</span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a>accuracy <span class="op">=</span> []</span>
<span id="cb12-6"><a href="#cb12-6" tabindex="-1"></a><span class="cf">for</span> depth <span class="kw">in</span> max_depths:</span>
<span id="cb12-7"><a href="#cb12-7" tabindex="-1"></a>    clf <span class="op">=</span> DecisionTreeClassifier(max_depth<span class="op">=</span>depth)</span>
<span id="cb12-8"><a href="#cb12-8" tabindex="-1"></a>    clf.fit(X_train, y_train)</span>
<span id="cb12-9"><a href="#cb12-9" tabindex="-1"></a>    acc <span class="op">=</span> clf.score(X_test, y_test)</span>
<span id="cb12-10"><a href="#cb12-10" tabindex="-1"></a></span>
<span id="cb12-11"><a href="#cb12-11" tabindex="-1"></a>    accuracy.append((depth, acc))</span>
<span id="cb12-12"><a href="#cb12-12" tabindex="-1"></a></span>
<span id="cb12-13"><a href="#cb12-13" tabindex="-1"></a>acc_df <span class="op">=</span> pd.DataFrame(accuracy, columns<span class="op">=</span>[<span class="st">'depth'</span>, <span class="st">'accuracy'</span>])</span>
<span id="cb12-14"><a href="#cb12-14" tabindex="-1"></a></span>
<span id="cb12-15"><a href="#cb12-15" tabindex="-1"></a>sns.lineplot(acc_df, x<span class="op">=</span><span class="st">'depth'</span>, y<span class="op">=</span><span class="st">'accuracy'</span>)</span>
<span id="cb12-16"><a href="#cb12-16" tabindex="-1"></a>plt.xlabel(<span class="st">'Tree depth'</span>)</span>
<span id="cb12-17"><a href="#cb12-17" tabindex="-1"></a>plt.ylabel(<span class="st">'Accuracy'</span>)</span>
<span id="cb12-18"><a href="#cb12-18" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<figure><img src="../fig/e3_dt_overfit.png" alt="A line plot showing the accuracy of decision trees with various max_depth hyper-parameters. The x-axis shows the max_depth, and the y-axis shows the accuracy. The accuracy is highest at max_depth=2." class="figure mx-auto d-block"><div class="figcaption">Performance of decision trees of various
depths</div>
</figure><p>It looks like a <code>max_depth=2</code> performs slightly better on
the test data than those with <code>max_depth &gt; 2</code>. This can
seem counter intuitive, as surely more questions should be able to
better split up our categories and thus give better predictions?</p>
<p>This is a classic case of over-fitting - our model has produced
extremely specific parameters that work for the training data but are
not necessarily representative of our test data.</p>
</div>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="inspecting-an-over-fitted-decision-tree">Inspecting an over-fitted decision tree<a class="anchor" aria-label="anchor" href="#inspecting-an-over-fitted-decision-tree"></a></h2>
<hr class="half-width"><p>Let’s reuse our fitting and plotting codes from above to inspect a
decision tree that has <code>max_depth=5</code>:</p>
<div class="codewrapper sourceCode" id="cb13">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a>clf <span class="op">=</span> DecisionTreeClassifier(max_depth<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a>clf.fit(X_train, y_train)</span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a>fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">10</span>))</span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a>plot_tree(clf, class_names<span class="op">=</span>class_names, feature_names<span class="op">=</span>feature_names, filled<span class="op">=</span><span class="va">True</span>, ax<span class="op">=</span>fig.gca())</span>
<span id="cb13-6"><a href="#cb13-6" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<figure><img src="../fig/e3_dt_6.png" alt="An automatically generated decision tree based on the model we just trained, showing how the model makes decisions based on the penguin features. The tree has 4 levels, and is difficult to read." class="figure mx-auto d-block"><div class="figcaption">Simplified decision tree</div>
</figure><p>It looks like our decision tree has split up the training data into
the correct penguin categories and more accurately than the
<code>max_depth=2</code> model did, however it used some very specific
questions to split up the penguins into the correct categories. Let’s
try visualising the classification space for a more intuitive
understanding:</p>
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a>f1 <span class="op">=</span> feature_names[<span class="dv">0</span>]</span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a>f2 <span class="op">=</span> feature_names[<span class="dv">3</span>]</span>
<span id="cb14-3"><a href="#cb14-3" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" tabindex="-1"></a>clf <span class="op">=</span> DecisionTreeClassifier(max_depth<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb14-5"><a href="#cb14-5" tabindex="-1"></a>clf.fit(X_train[[f1, f2]], y_train)</span>
<span id="cb14-6"><a href="#cb14-6" tabindex="-1"></a></span>
<span id="cb14-7"><a href="#cb14-7" tabindex="-1"></a>d <span class="op">=</span> DecisionBoundaryDisplay.from_estimator(clf, X_train[[f1, f2]])</span>
<span id="cb14-8"><a href="#cb14-8" tabindex="-1"></a></span>
<span id="cb14-9"><a href="#cb14-9" tabindex="-1"></a>sns.scatterplot(X_train, x<span class="op">=</span>f1, y<span class="op">=</span>f2, hue<span class="op">=</span>y_train, palette<span class="op">=</span><span class="st">'husl'</span>)</span>
<span id="cb14-10"><a href="#cb14-10" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<figure><img src="../fig/e3_dt_space_6.png" alt="A scatter plot of the penguin daaset, showing bill length on the x-axis and body mass on the y-axis. The points are coloured by species. The decision tree is shown as colored regions, with the boundaries between the regions being orthogonal lines. The regions are generally aligned with the species clusters, but there are many small regions that only select a single point." class="figure mx-auto d-block"><div class="figcaption">Classification space of the simplified decision
tree</div>
</figure><p>Earlier we saw that the <code>max_depth=2</code> model split the data
into 3 simple bounding boxes, whereas for <code>max_depth=5</code> we
see the model has created some very specific classification boundaries
to correctly classify every point in the training data.</p>
<p>This is a classic case of over-fitting - our model has produced
extremely specific parameters that work for the training data but are
not representitive of our test data. Sometimes simplicity is better!</p>
</section><section><h2 class="section-heading" id="classification-using-support-vector-machines">Classification using support vector machines<a class="anchor" aria-label="anchor" href="#classification-using-support-vector-machines"></a></h2>
<hr class="half-width"><p>Next, we’ll look at another commonly used classification algorithm,
and see how it compares. Support Vector Machines (SVM) work in a way
that is conceptually similar to your own intuition when first looking at
the data. They devise a set of hyperplanes that delineate the parameter
space, such that each region contains ideally only observations from one
class, and the boundaries fall between classes.</p>
<div class="section level3">
<h3 id="normalising-data">Normalising data<a class="anchor" aria-label="anchor" href="#normalising-data"></a></h3>
<p>Unlike decision trees, SVMs require an additional pre-processing step
for our data. We need to normalise it. Our raw data has parameters with
different magnitudes such as bill length measured in 10’s of mm’s,
whereas body mass is measured in 1000’s of grams. If we trained an SVM
directly on this data, it would only consider the parameter with the
greatest variance (body mass).</p>
<p>Normalising maps each parameter to a new range so that it has a mean
of 0 and a standard deviation of 1.</p>
<div class="codewrapper sourceCode" id="cb15">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> preprocessing</span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb15-3"><a href="#cb15-3" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" tabindex="-1"></a>scalar <span class="op">=</span> preprocessing.StandardScaler()</span>
<span id="cb15-5"><a href="#cb15-5" tabindex="-1"></a>scalar.fit(X_train)</span>
<span id="cb15-6"><a href="#cb15-6" tabindex="-1"></a>X_train_scaled <span class="op">=</span> pd.DataFrame(scalar.transform(X_train), columns<span class="op">=</span>X_train.columns, index<span class="op">=</span>X_train.index)</span>
<span id="cb15-7"><a href="#cb15-7" tabindex="-1"></a>X_test_scaled <span class="op">=</span> pd.DataFrame(scalar.transform(X_test), columns<span class="op">=</span>X_test.columns, index<span class="op">=</span>X_test.index)</span></code></pre>
</div>
<p>Note that we fit the scalar to our training data - we then use this
same pre-trained scalar to transform our testing data.</p>
<p>With this scaled data, training the models works exactly the same as
before.</p>
<div class="codewrapper sourceCode" id="cb16">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> svm</span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" tabindex="-1"></a>SVM <span class="op">=</span> svm.SVC(kernel<span class="op">=</span><span class="st">'poly'</span>, degree<span class="op">=</span><span class="dv">3</span>, C<span class="op">=</span><span class="fl">1.5</span>)</span>
<span id="cb16-4"><a href="#cb16-4" tabindex="-1"></a>SVM.fit(X_train_scaled, y_train)</span>
<span id="cb16-5"><a href="#cb16-5" tabindex="-1"></a></span>
<span id="cb16-6"><a href="#cb16-6" tabindex="-1"></a>svm_score <span class="op">=</span> SVM.score(X_test_scaled, y_test)</span>
<span id="cb16-7"><a href="#cb16-7" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Decision tree score is "</span>, clf_score)</span>
<span id="cb16-8"><a href="#cb16-8" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"SVM score is "</span>, svm_score)</span></code></pre>
</div>
<p>We can again visualise the decision space produced, also using only
two parameters:</p>
<div class="codewrapper sourceCode" id="cb17">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a>x2 <span class="op">=</span> X_train_scaled[[feature_names[<span class="dv">0</span>], feature_names[<span class="dv">1</span>]]]</span>
<span id="cb17-2"><a href="#cb17-2" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" tabindex="-1"></a>SVM <span class="op">=</span> svm.SVC(kernel<span class="op">=</span><span class="st">'poly'</span>, degree<span class="op">=</span><span class="dv">3</span>, C<span class="op">=</span><span class="fl">1.5</span>)</span>
<span id="cb17-4"><a href="#cb17-4" tabindex="-1"></a>SVM.fit(x2, y_train)</span>
<span id="cb17-5"><a href="#cb17-5" tabindex="-1"></a></span>
<span id="cb17-6"><a href="#cb17-6" tabindex="-1"></a>DecisionBoundaryDisplay.from_estimator(SVM, x2) <span class="co">#, ax=ax</span></span>
<span id="cb17-7"><a href="#cb17-7" tabindex="-1"></a>sns.scatterplot(x2, x<span class="op">=</span>feature_names[<span class="dv">0</span>], y<span class="op">=</span>feature_names[<span class="dv">1</span>], hue<span class="op">=</span>dataset[<span class="st">'species'</span>])</span>
<span id="cb17-8"><a href="#cb17-8" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<figure><img src="../fig/e3_svc_space.png" alt="A scatter plot of the penguin daaset, showing bill length on the x-axis and bill depth on the y-axis. The points are coloured by species. The SVM is shown as colored regions, with the boundaries between the regions being curved lines. The regions are generally aligned with the species clusters, but there are still several misclassifications." class="figure mx-auto d-block"><div class="figcaption">Classification space generated by the SVM
model</div>
</figure><p>While this SVM model performs slightly worse than our decision tree
(95.6% vs. 98.5%), it’s likely that the non-linear boundaries will
perform better when exposed to more and more real data, as decision
trees are prone to overfitting and requires complex linear models to
reproduce simple non-linear boundaries. It’s important to pick a model
that is appropriate for your problem and data trends!</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points</h3>
<div class="callout-content">
<ul><li>Classification requires labelled data (is supervised).</li>
</ul></div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</div>
</section></div> <!-- / div.lesson-content -->
    </main><!-- / main#main-content.main-content --><nav class="bottom-pagination mx-md-4" aria-label="Previous and Next Chapter"><div class="d-block d-sm-block d-md-none">
        <a class="chapter-link" href="../instructor/02-regression.html"><i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>Previous</a>
        <a class="chapter-link float-end" href="../instructor/04-ensemble-methods.html">Next<i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i></a>
      </div>
      <!-- content for large screens -->
      <div class="d-none d-sm-none d-md-block">
        <a class="chapter-link" href="../instructor/02-regression.html" rel="prev">
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>
          Previous: Supervised methods -
        </a>
        <a class="chapter-link float-end" href="../instructor/04-ensemble-methods.html" rel="next">
          Next: Ensemble methods...
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i>
        </a>
      </div>
    </nav></div> <!-- / div.primary-content.col-xs-12 -->
<!-- END:   inst/pkgdown/templates/content-instructor.html-->

      </div><!--/div.row-->
      		<footer class="row footer mx-md-3"><hr><div class="col-md-6">
        <p>This lesson is subject to the <a href="CODE_OF_CONDUCT.html">Code of Conduct</a></p>
        <p>

        <a href="https://github.com/jonathan-hartman/machine-learning-novice-sklearn/edit/main/episodes/03-classification.md" class="external-link">Edit on GitHub</a>

	
        | <a href="https://github.com/jonathan-hartman/machine-learning-novice-sklearn/blob/main/CONTRIBUTING.md" class="external-link">Contributing</a>
        | <a href="https://github.com/jonathan-hartman/machine-learning-novice-sklearn/" class="external-link">Source</a></p>
				<p><a href="https://github.com/jonathan-hartman/machine-learning-novice-sklearn/blob/main/CITATION.cff" class="external-link">Cite</a> | <a href="mailto:hartman@itc.rwth-aachen.de">Contact</a> | <a href="https://carpentries.org/about/" class="external-link">About</a></p>
			</div>
			<div class="col-md-6">

        <p>Materials licensed under <a href="LICENSE.html">CC-BY 4.0</a> by the authors</p>

        <p>Template licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/" class="external-link">CC-BY 4.0</a> by <a href="https://carpentries.org/" class="external-link">The Carpentries</a></p>
        <p>Built with <a href="https://github.com/carpentries/sandpaper/tree/0.16.12" class="external-link">sandpaper (0.16.12)</a>, <a href="https://github.com/carpentries/pegboard/tree/0.7.9" class="external-link">pegboard (0.7.9)</a>, and <a href="https://github.com/carpentries/varnish/tree/1.0.6" class="external-link">varnish (1.0.6)</a></p>
			</div>
		</footer></div> <!-- / div.container -->
	<div id="to-top">
		<a href="#top">
      <i class="search-icon" data-feather="arrow-up" role="img" aria-label="Back To Top"></i><br><!-- <span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top --><span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top
		</a>
	</div>
  <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "LearningResource",
  "@id": "https://jonathan-hartman.github.io/machine-learning-novice-sklearn/instructor/03-classification.html",
  "inLanguage": "en",
  "dct:conformsTo": "https://bioschemas.org/profiles/LearningResource/1.0-RELEASE",
  "description": "A Carpentries Lesson teaching foundational data and coding skills to researchers worldwide",
  "keywords": "machine learning, python, sklearn, The Carpentries",
  "name": "Supervised methods - Classification",
  "creativeWorkStatus": "active",
  "url": "https://jonathan-hartman.github.io/machine-learning-novice-sklearn/instructor/03-classification.html",
  "identifier": "https://jonathan-hartman.github.io/machine-learning-novice-sklearn/instructor/03-classification.html",
  "dateCreated": "2025-07-23",
  "dateModified": "2025-07-23",
  "datePublished": "2025-07-23"
}

  </script><script>
		feather.replace();
	</script></body></html><!-- END:   inst/pkgdown/templates/layout.html-->

